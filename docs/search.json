[
  {
    "objectID": "ASME_08.html",
    "href": "ASME_08.html",
    "title": "8: Cox Regression",
    "section": "",
    "text": "Show the code\n# read \"dta\" files\nlibrary(haven) \n# create table\nlibrary(gtsummary)\n# data wrangling and other functions\nlibrary(tidyverse)\n# if you want to have a output similar to stata\nlibrary(tidylog)\n#cox\nlibrary(survival)\n# plots survival\nlibrary(ggsurvfit)\n# Limit significant digits to 2, remove scientific notation\noptions(digits = 2, scipen = 9)\n\n# Import the dataset\ntrin &lt;- read_dta(\"datasets/TRINMLSH.DTA\")\n\n#This contains data from a cohort study on cardiovascular risk factors and mortality among ~300 men from Trinidad.\n# Some data wrangling\n\ntrin &lt;- trin |&gt; \n  mutate(\n    ethgp = factor(ethgp,\n                      levels = c(1:5),\n                      labels = c(\"African\", \"Indian\", \"European\", \"mixed\", \"Chin/Sem\")),\n    alc = factor(alc,\n                      levels = c(0:3),\n                      labels = c(\"none\", \"1-4/wk\", \"5-14/wk\", \"&gt;=15/wk\")),\n    smoke3 = case_when(\n      smokenum == 0 ~ \"non-smok\",\n      smokenum == 1 ~ \"ex-smok\",\n      !is.na(smokenum) ~ \"smoker\"\n    ),\n    smoke3 = fct_relevel(smoke3, \"non-smok\"),\n    smokenum = factor(smokenum,\n                      levels = c(0:5),\n                      labels = c(\"non-smok\", \"ex-smok\", \"1-9/d\", \"10-19/d\", \"20-29/d\", \"&gt;=30/d\")),\n    chdstart = factor(chdstart,\n                      levels = c(0, 1),\n                      labels = c(\"no\", \"yes\")\n    ))\n\n\n\nQ1\nThe variables timein and timeout hold the dates of entry and exit into the study, while death is the indicator for mortality from any cause. Use stset with these variables, setting timein to be the origin (i.e. sort the records according to follow-up time, as in Figure 4).\nYou don’t need to do any of this (stset) in R. Each regression can have its own time setting!\n\n\nQ2\nExamine the effect of smoking on all-cause mortality using strate (or stptime if you prefer) and stcox. You may wish to recode smokenum into a smaller number of categories, say: 0=non-smoker, 1=ex-smoker, 2=current smoker.\nWe can now examine the smoking-specific mortality rates (per 1,000 person-years). Let’s first use the classical technique and then let’s use Cox regression.\n\nShow the code\n# Calculate rates\npyears(Surv(time = years, event=death) ~ smoke3, data = trin, scale = 1) %&gt;%\n  summary(n = F, rate = T, ci.r = T, scale = 1000)\n\nCall: pyears(formula = Surv(time = years, event = death) ~ smoke3, data = trin, scale = 1)\nnumber of observations = 317\n\n\n\nsmoke3\nEvents\nTime\nEvent rate\nCI (rate)\n\n\n\n\nnon-smok\n30\n984\n30\n21 - 44\n\n\nex-smok\n18\n462\n39\n23 - 62\n\n\nsmoker\n40\n749\n53\n38 - 73\n\n\n\n\nShow the code\n# Note that Surv() can take time data in two different formats: either a combination of data of entry and data of exit, or as a time # difference. In this case, `years` codes this time difference, so we'll use it.\n\n# Create Cox model\ncox_smok3 &lt;- coxph(Surv(time = years, event=death) ~ smoke3, data = trin)\n\n# Calculating 95% CIs for HRs\ntbl_regression(cox_smok3, exponentiate = T) |&gt; \n  add_n(location=\"level\") |&gt; \n  add_nevent(location=\"level\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nEvent N\nHR\n95% CI\np-value\n\n\n\n\nsmoke3\n\n\n\n\n\n\n\n\n\n\n\n\n    non-smok\n140\n30\n—\n—\n\n\n\n\n    ex-smok\n68\n18\n1.29\n0.72, 2.32\n0.4\n\n\n    smoker\n109\n40\n1.75\n1.09, 2.81\n0.021\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\nN is the size of the group\nEvent N is the number of events in that group\n\n\n\nQ3\nUsing the rates and rate ratios in part (2), can you see a trend in the relationship between smoking category and all-cause mortality? How would you assess this more formally? How would you present the results from your analyses in parts (2) and (3)?\n\n\nShow the code\n# Create Cox model\ncox_smok3 &lt;- coxph(Surv(time = years, event=death) ~ as.numeric(smoke3), data = trin)\n\n# Calculating 95% CIs for HRs\ntbl_regression(cox_smok3, exponentiate = T) |&gt; \n  add_n(location=\"level\") |&gt; \n  add_nevent(location=\"level\")\n\n\n\n\n\n\n\n\nCharacteristic\nN\nEvent N\nHR\n95% CI\np-value\n\n\n\n\nas.numeric(smoke3)\n317\n88\n1.32\n1.04, 1.68\n0.020\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou can assess the trend formally by treating the smoke variable as numeric (ordinal in this case), so the model will evaluate if the increase in each point is associated with increase in the hazard.\n\n\n\n\n\nQ4\nConsider the possible confounding effect of current age on the relationship between smoking and mortality. By examining the data (but without performing any further modelling) would you expect a Cox model controlling for current age to give different results to one controlling for time in the study? Now perform a Cox model to investigate this.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nNote that in question 2 the Cox model has adjusted for time in the study i.e. everyone is followed up from the time they enter the study and when an event occurs the comparison is with others who have the same amount of follow-up and not with others of the same age. If there are differences in age between the three groups then we would expect an analysis controlling for current age to show confounding (since mortality increases with age). One indicator of this would be the age at entry in the three groups.\n\n\n\n\n\nShow the code\ntrin |&gt; \n  tbl_summary(include = ageent, by = smoke3) |&gt; \n  modify_caption(\"Age by smoke status\")\n\n\n\n\n\n\nAge by smoke status\n\n\n\n\n\n\n\n\nCharacteristic\nnon-smok N = 1401\nex-smok N = 681\nsmoker N = 1091\n\n\n\n\nAge in years at first survey\n64.52 (62.32, 67.68)\n65.32 (62.47, 68.73)\n64.40 (62.48, 66.44)\n\n\n\n1 Median (Q1, Q3)\n\n\n\n\n\n\n\n\nShow the code\n# Survival object set for current age\n# Cox using the timeage as the time \ncox_smok3_age &lt;- coxph(Surv(time=as.numeric(timein),time2=as.numeric(timeout),\n                             event = death,\n                             origin = as.numeric(timebth)) ~ smoke3, data = trin)\n\ntbl_regression(cox_smok3_age, exponentiate = T) |&gt; \n  add_n(location=\"level\") |&gt; \n  add_nevent(location=\"level\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nEvent N\nHR\n95% CI\np-value\n\n\n\n\nsmoke3\n\n\n\n\n\n\n\n\n\n\n\n\n    non-smok\n140\n30\n—\n—\n\n\n\n\n    ex-smok\n68\n18\n1.28\n0.71, 2.29\n0.4\n\n\n    smoker\n109\n40\n1.77\n1.10, 2.85\n0.018\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\n\nQ5\nUsing PBC1BAS dataset\n\n\nShow the code\n# some data wrangling\n# Read in the pbc1bas.dta dataset \npbc &lt;- read_dta(\"datasets/PBC1BAS.DTA\")\n\n# Data management\npbc&lt;- pbc |&gt; mutate(death = d,\n               treat = factor(treat, levels = c(1, 2), labels = c(\"placebo\", \"azath\")),\n               cenc0 = factor(cenc0, levels = c(0, 1), labels = c(\"no\", \"yes\")),\n               cir0 = factor(cir0, levels = c(0, 1), labels = c(\"no\", \"yes\")),\n               gh0 = factor(gh0, levels = c(0, 1), labels = c(\"no\", \"yes\")),\n               asc0 = factor(asc0, levels = c(0, 1), labels = c(\"no\", \"yes\"))) |&gt; \n         select(-d)\n\n\nUse a Poisson model to assess the relationship between treatment and mortality adjusting for baseline bilirubin (logb0). How do the results compare to those from using a Cox model?\n\n\nShow the code\n# Poisson model\nmod_pois &lt;- glm(death ~ offset(log(time)) + treat + logb0, family = poisson, data = pbc) \n\ntbl_pois &lt;- tbl_regression(mod_pois,exponentiate = T)\n\n# Cox model\nmod_cox &lt;- coxph(Surv(time,death) ~ treat + logb0, data = pbc)\ntbl_cox &lt;- tbl_regression(mod_cox,exponentiate = T)\n\ntbl_merge(list(tbl_pois,tbl_cox))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nTable 1\n\n\nTable 2\n\n\n\nIRR\n95% CI\np-value\nHR\n95% CI\np-value\n\n\n\n\ntreat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    placebo\n—\n—\n\n\n—\n—\n\n\n\n\n    azath\n0.73\n0.49, 1.10\n0.13\n0.65\n0.43, 0.99\n0.044\n\n\nLob Bilirubin at entry\n7.23\n4.64, 11.3\n&lt;0.001\n10.6\n6.42, 17.6\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nShow the code\ntbl_merge(list(tbl_pois,tbl_cox),\n          tab_spanner = c(\"**Poisson**\", \"**Cox**\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nPoisson\n\n\nCox\n\n\n\nIRR\n95% CI\np-value\nHR\n95% CI\np-value\n\n\n\n\ntreat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    placebo\n—\n—\n\n\n—\n—\n\n\n\n\n    azath\n0.73\n0.49, 1.10\n0.13\n0.65\n0.43, 0.99\n0.044\n\n\nLob Bilirubin at entry\n7.23\n4.64, 11.3\n&lt;0.001\n10.6\n6.42, 17.6\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe results from the Cox model provide more evidence for an impact of treatment (from the hazard ratios, 95% CIs and the p-values). However, the Cox model adjusts for time in the study as well as baseline bilirubin whereas the Poisson model adjusts for baseline bilirubin only.\n\n\n\n\n\nQ6\nIn order to make a like for like comparison with the Cox model, what would be a more appropriate analysis using streg (survSplit in R / other functions (see Epi package)) and what do the results from this analysis indicate?\n\n\nShow the code\n# Split the survival object\npbc_split &lt;- survSplit(Surv(time,death) ~ .,\n                       data = pbc,\n                       cut = c(2, 4, 6),\n                       episode = \"period\",\n                       start = \"tstart\",\n                       end = \"tstop\")\n\n# Fix age and create follow-up by band\npbc_split &lt;- pbc_split |&gt; \n  mutate(\n    age = age + tstart,\n    t_fup = tstop - tstart\n  )\n\n\n# Factorise variable and label values\npbc_split$period &lt;- factor(pbc_split$period,\n                           levels = c(1, 2, 3, 4),\n                           labels = c(\"0-2y\", \"2-4y\", \"4-6y\", \"6-12y\"))\nglm(death ~ offset(log(t_fup)) + treat + logb0 + period,   # period goes here\n    family = poisson(),\n    data = pbc_split) |&gt; \n  tbl_regression(exponentiate = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\ntreat\n\n\n\n\n\n\n\n\n    placebo\n—\n—\n\n\n\n\n    azath\n0.64\n0.42, 0.96\n0.032\n\n\nlogb0\n11.1\n6.78, 18.4\n&lt;0.001\n\n\nperiod\n\n\n\n\n\n\n\n\n    0-2y\n—\n—\n\n\n\n\n    2-4y\n1.21\n0.70, 2.05\n0.5\n\n\n    4-6y\n2.46\n1.38, 4.28\n0.002\n\n\n    6-12y\n4.67\n2.39, 8.84\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nIf you split the time in a more granular way, the results will be even closer!\n\n\nShow the code\n# Split the survival object\npbc_split &lt;- survSplit(Surv(time,death) ~ .,\n                       data = pbc,\n                       cut = c(2,3,4,5,6,7,8,9),\n                       episode = \"period\",\n                       start = \"tstart\",\n                       end = \"tstop\")\n\n# Fix age and create follow-up by band\npbc_split &lt;- pbc_split |&gt; \n  mutate(\n    age = age + tstart,\n    t_fup = tstop - tstart\n  )\n\n\n# Factorise variable and label values\npbc_split$period &lt;- as.factor(pbc_split$period)\nglm(death ~ offset(log(t_fup)) + treat + logb0 + period,   # period goes here\n    family = poisson(),\n    data = pbc_split) |&gt; \n  tbl_regression(exponentiate = T, include = treat)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\ntreat\n\n\n\n\n\n\n\n\n    placebo\n—\n—\n\n\n\n\n    azath\n0.65\n0.43, 0.98\n0.040\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\n\n\nQ7\nUse a Cox regression model to estimate the effect of grade (coded: 1=high; 2=low) using first the follow-up time scale. Then check whether current age is a confounder using both Cox and Poisson regression.\n\n\nShow the code\nwhitehall &lt;- read_stata(\"datasets/WHITEHAL.DTA\")\n\n# Factorise job grade\nwhitehall$grade &lt;- factor(whitehall$grade,\n                          levels = c(1, 2),\n                          labels = c(\"higher\", \"lower\"))\n\n\n\n\nShow the code\n# Cox\ncox_time &lt;- coxph(Surv(\n  as.numeric(timein),\n  as.numeric(timeout),\n  event = chd\n) ~ grade, data = whitehall)\n\ntbl_time &lt;- tbl_regression(cox_time, exponentiate = T)\n# Cox\ncox_age &lt;- coxph(Surv(\n  as.numeric(timein),\n  as.numeric(timeout),\n  event = chd,\n  origin = as.numeric(timebth)\n) ~ grade, data = whitehall)\ntbl_age &lt;- tbl_regression(cox_age, exponentiate = T)\n\ntbl_merge(list(tbl_time,tbl_age),\n         tab_spanner = c(\"**Time since followup**\", \"**Age**\") )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nTime since followup\n\n\nAge\n\n\n\nHR\n95% CI\np-value\nHR\n95% CI\np-value\n\n\n\n\ngrade\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    higher\n—\n—\n\n\n—\n—\n\n\n\n\n    lower\n2.04\n1.48, 2.81\n&lt;0.001\n1.41\n1.01, 1.95\n0.043\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Split the survival object\nsplit_white &lt;- survSplit(Surv(\n  as.numeric(timein),\n  as.numeric(timeout),\n  event = chd,\n  origin = as.numeric(timebth)\n) ~ .,\n                         data = whitehall,\n                         cut = c(50*365.25, 60*365.25, 70*365.25,\n                                 80*365.25),\n                         episode = \"age\",\nstart = \"tstart\",\nend = \"tstop\")\n\n# Factorise variable and label values\nsplit_white$age &lt;- factor(split_white$age,\n                          levels = c(1, 2, 3, 4,5),\n                          labels = c(\"&lt;=50\", \"51-60\", \"61-70\", \n                                     \"71-80\",\n                                     \"&gt;80\"))\n\nsplit_white &lt;- split_white  |&gt; \n  mutate(\n    pyears=as.numeric(tstop - tstart))\n\n#Fit a Poisson model\nglm(chd ~ offset(log(pyears)) + grade + age,   \n    family = poisson(),\n    data = split_white) |&gt; \n  tbl_regression(exponentiate = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\ngrade\n\n\n\n\n\n\n\n\n    higher\n—\n—\n\n\n\n\n    lower\n1.45\n1.04, 2.01\n0.027\n\n\nage\n\n\n\n\n\n\n\n\n    &lt;=50\n—\n—\n\n\n\n\n    51-60\n7.67\n1.63, 137\n0.045\n\n\n    61-70\n22.1\n4.90, 390\n0.002\n\n\n    71-80\n36.6\n7.95, 649\n&lt;0.001\n\n\n    &gt;80\n87.7\n12.9, 1,723\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\n\n\nOptional\nThink whether you should test for interaction between grade and current age. If so how would you do this using a Poisson model and what are the problems of assessing such an interaction using a Cox model?\n\n\nShow the code\n#Fit a Poisson model\npoisson_without &lt;- glm(chd ~ offset(log(pyears)) + grade + age,   \n    family = poisson(),\n    data = split_white)\npoisson_interaction &lt;- glm(chd ~ offset(log(pyears)) + grade * age,   \n    family = poisson(),\n    data = split_white)\nlmtest::lrtest(poisson_without,poisson_interaction)\n\n\n\n\n\n\n#Df\nLogLik\nDf\nChisq\nPr(&gt;Chisq)\n\n\n\n\n6\n-748\nNA\nNA\nNA\n\n\n10\n-741\n4\n13\n0.01\n\n\n\n\n\n\nYou can also test that with cox regression. If the model is using age as the underlying timescale. The survival packages has inbuilt function for that. The cox.zph function will test proportionality of all the predictors in the model by creating interactions with time using the transformation of time (default is log) specified in the transform option. And you can also plot the effect by time\n\n\nShow the code\ncox.zph(cox_age)\n\n\n       chisq df     p\ngrade   6.23  1 0.013\nGLOBAL  6.23  1 0.013\n\n\nShow the code\nplot(cox.zph(cox_age))",
    "crumbs": [
      "8: Cox Regression"
    ]
  },
  {
    "objectID": "ASME_09.html",
    "href": "ASME_09.html",
    "title": "09: Further issues in analysis of cohort studies",
    "section": "",
    "text": "Show the code\nlibrary(haven) \n# create table\nlibrary(gtsummary)\n# data wrangling and other functions\nlibrary(tidyverse)\n# if you want to have a output similar to stata\nlibrary(tidylog)\n#cox\nlibrary(survival)\n# plots survival\nlibrary(ggsurvfit)\n# Limit significant digits to 2, remove scientific notation\noptions(digits = 2, scipen = 9)\n\ndiet &lt;- read_dta(\"datasets/DIETLSH.dta\") |&gt; \n  mutate(across(where(is.labelled),as_factor))\n\ndiet &lt;- diet |&gt; \n  mutate(hieng = factor(hieng,\n                                levels = c(0, 1),\n                                labels = c(\"normal\", \"high-energy\")),\n                 fibre_cat = cut_number(fibre, 3))\n\n\n\nQ1\nUse the data in dietlsh.dta to estimate the effect of hieng on chd when the time scale is set equal to time since entry using stcox.\n\n\nShow the code\n# Create Cox model\ncox_mod &lt;- coxph(Surv(time = fup, event=chd) ~ hieng, data = diet)\n\n# Calculating 95% CIs for HRs\ntbl_regression(cox_mod, exponentiate = T) |&gt; \n  add_n(location=\"level\") |&gt; \n  add_nevent(location=\"level\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nEvent N\nHR\n95% CI\np-value\n\n\n\n\nhieng\n\n\n\n\n\n\n\n\n\n\n\n\n    normal\n155\n28\n—\n—\n\n\n\n\n    high-energy\n182\n18\n0.52\n0.29, 0.95\n0.032\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\n\nQ2\nExamine the proportionality assumption using a Nelson-Aalen plot. Does the proportionality assumption appear to be valid?\n\n\nShow the code\nsurvfit2(Surv(time = fup, event=chd) ~ hieng, data = diet) |&gt; \n  ggsurvfit(\n    type = \"cumhaz\"\n  )+\n  scale_y_log10()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nOn this time scale the effect of hieng appears to be proportional as the two lines are quite parallel.\n\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nNelson-Aalen plot is the plot in the cumulative hazard. The ggsurvfit function accept multiple statistics: “survival” (KM plot), “risk” (Cumulative incidence), “cumhaz” (NA plot), “cloglog” (complimentary log-log survival). It is necessary to transform the Y axis to the log scale. (The PH assumption is in log)\n\n\n\n\n\nQ3\nDoes an interaction test confirm your conclusions?\n\n\nShow the code\ncox.zph(coxph(Surv(time = fup, event=chd) ~ hieng, data = diet))\n\n\n       chisq df    p\nhieng  0.881  1 0.35\nGLOBAL 0.881  1 0.35\n\n\nShow the code\nplot(cox.zph(coxph(Surv(time = fup, event=chd) ~ hieng, data = diet)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is little evidence that the effect of hieng is not proportional using time in the study.\n\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nThe answer in STATA praticals is using stsplit-spliting the dataset by time since fup- and doing a interaction. In R, we have cox.zph which fits a model with interaction between time and each covariate in the model. And it is possible to visualize the time-varying coefficient\n\n\n\n\n\nQ4/Q5\nRe-examine Question 1 and Question 2 using attained age as the time-scale. Is the proportionality assumption valid? What are the problems with assessing proportionality using graphical methods when using age as the time-scale?\nAssess the proportionality assumption by including an interaction between time period and hieng.\n\n\nShow the code\ncox_mod &lt;- coxph(Surv(time = as.numeric(doe), \n                      time2 = as.numeric(dox),\n                      origin = as.numeric(dob),\n                      event=chd) ~ hieng, data = diet)\ntbl_regression(cox_mod, exponentiate = T) |&gt; \n  add_n(location=\"level\") |&gt; \n  add_nevent(location=\"level\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nEvent N\nHR\n95% CI\np-value\n\n\n\n\nhieng\n\n\n\n\n\n\n\n\n\n\n\n\n    normal\n155\n28\n—\n—\n\n\n\n\n    high-energy\n182\n18\n0.54\n0.30, 0.98\n0.043\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\nNA plots\n\n\nShow the code\nsurvfit2(Surv(time = as.numeric(doe)/365.25, \n                      time2 = as.numeric(dox)/365.25,\n                      origin = as.numeric(dob)/365.25,\n                      event=chd) ~ hieng, data = diet) |&gt; \n  ggsurvfit(\n    type = \"cumhaz\"\n  )+\n  scale_y_log10()\n\n\n\n\n\n\n\n\n\nInteraction plots\n\n\nShow the code\ncox.zph(cox_mod)\n\n\n       chisq df   p\nhieng  0.698  1 0.4\nGLOBAL 0.698  1 0.4\n\n\nShow the code\nplot(cox.zph(cox_mod))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe estimated effect of hieng has not really changed but the effect does not appear to be proportional on this scale. However, in using attained age as the time-scale there are few individuals at the beginning of follow-up (the median age for entry into the study was 48.8 years). Therefore when early events occur they are based on few individuals and so the hazard estimates are less reliable here which impacts on the cumulative event rates over the course of follow-up. For this reason Nelson-Aalen plots are most useful when there is no delayed entry e.g. when the time-scale is time since entry into the study.\n\n\n\n\n\nQ6\nCreate a categorical variable (fibcat3) containing the fibre content of the diet in thirds. Examine the effect of fibcat3, first using time since entry and then attained age as time-scale.\n\n\nShow the code\ncox_mod_fup &lt;- coxph(Surv(time = fup, \n                      event=chd) ~ fibre_cat, data = diet)\ntbl_fup &lt;- tbl_regression(cox_mod_fup, exponentiate = T) |&gt; \n  add_n(location=\"level\") |&gt; \n  add_nevent(location=\"level\")\n\ncox_mod_age &lt;- coxph(Surv(time = as.numeric(doe), \n                      time2 = as.numeric(dox),\n                      origin = as.numeric(dob),\n                      event=chd) ~ fibre_cat, data = diet)\ntbl_age &lt;- tbl_regression(cox_mod_age, exponentiate = T) |&gt; \n  add_n(location=\"level\") |&gt; \n  add_nevent(location=\"level\")\n\ntbl_merge(list(\n  tbl_fup,\n  tbl_age\n  ),\n         tab_spanner = c(\"**Time since entry**\", \"**Age**\") )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nTime since entry\n\n\nAge\n\n\n\nN\nEvent N\nHR\n95% CI\np-value\nN\nEvent N\nHR\n95% CI\np-value\n\n\n\n\nfibre_cat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    [0.605,1.45]\n112\n21\n—\n—\n\n\n112\n21\n—\n—\n\n\n\n\n    (1.45,1.83]\n110\n17\n0.82\n0.43, 1.56\n0.6\n110\n17\n0.79\n0.42, 1.50\n0.5\n\n\n    (1.83,5.35]\n111\n7\n0.29\n0.12, 0.68\n0.005\n111\n7\n0.29\n0.12, 0.69\n0.005\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\nAssess proportionality\nTime since entry\n\n\nShow the code\ncox.zph(cox_mod_fup)\n\n\n          chisq df    p\nfibre_cat 0.251  2 0.88\nGLOBAL    0.251  2 0.88\n\n\nShow the code\nplot(cox.zph(cox_mod_fup))\n\n\n\n\n\n\n\n\n\nAge\n\n\nShow the code\ncox.zph(cox_mod_fup)\n\n\n          chisq df    p\nfibre_cat 0.251  2 0.88\nGLOBAL    0.251  2 0.88\n\n\nShow the code\nplot(cox.zph(cox_mod_fup))\n\n\n\n\n\n\n\n\n\n\n\nQ7\nUse the PBC data set: pbc1bas.dta. Set the time and failure variables as in ASME 7, section 3 (i.e. with time in the study as the time scale) and then examine separately the effects of treatment, bilirubin and cirrhosis. What assumptions are you making? Fit a multivariate model with these three variables. What happens to the estimated rate ratios? Is this the most appropriate time scale to use?\n\n\nShow the code\npbc &lt;- read_dta(\"datasets/PBC1BAS.DTA\")\n\n# Data management\npbc&lt;- pbc |&gt; mutate(death = d,\n               treat = factor(treat, levels = c(1, 2), labels = c(\"placebo\", \"azath\")),\n               cenc0 = factor(cenc0, levels = c(0, 1), labels = c(\"no\", \"yes\")),\n               cir0 = factor(cir0, levels = c(0, 1), labels = c(\"no\", \"yes\")),\n               gh0 = factor(gh0, levels = c(0, 1), labels = c(\"no\", \"yes\")),\n               asc0 = factor(asc0, levels = c(0, 1), labels = c(\"no\", \"yes\"))) |&gt; \n         select(-d)\n\n\n\n\nShow the code\nmod_tto &lt;- coxph(Surv(time,death) ~ treat, data = pbc)\nmod_tto1 &lt;- coxph(Surv(time,death) ~ treat+logb0, data = pbc)\nmod_tto2 &lt;- coxph(Surv(time,death) ~ treat+logb0+cir0, data = pbc)\n\ntbl_tto &lt;- tbl_regression(mod_tto, exponentiate = T) |&gt; \n  add_n(location=\"level\") |&gt; \n  add_nevent(location=\"level\")\ntbl_tto1 &lt;- tbl_regression(mod_tto1, exponentiate = T) |&gt; \n  add_n(location=\"level\") |&gt; \n  add_nevent(location=\"level\")\ntbl_tto2 &lt;- tbl_regression(mod_tto2, exponentiate = T) |&gt; \n  add_n(location=\"level\") |&gt; \n  add_nevent(location=\"level\")\ntbl_merge(list(tbl_tto,tbl_tto1,tbl_tto2),\n          tab_spanner = c(\"**Treat**\", \"**Treat+bili**\",\"**Treat+bili+cirr**\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nTreat\n\n\nTreat+bili\n\n\nTreat+bili+cirr\n\n\n\nN\nEvent N\nHR\n95% CI\np-value\nN\nEvent N\nHR\n95% CI\np-value\nN\nEvent N\nHR\n95% CI\np-value\n\n\n\n\ntreat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    placebo\n90\n49\n—\n—\n\n\n90\n49\n—\n—\n\n\n90\n49\n—\n—\n\n\n\n\n    azath\n94\n47\n0.86\n0.57, 1.28\n0.5\n94\n47\n0.65\n0.43, 0.99\n0.044\n94\n47\n0.63\n0.42, 0.96\n0.031\n\n\nLob Bilirubin at entry\n\n\n\n\n\n\n\n\n\n\n184\n96\n10.6\n6.42, 17.6\n&lt;0.001\n184\n96\n11.4\n6.68, 19.6\n&lt;0.001\n\n\ncir0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    no\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n131\n58\n—\n—\n\n\n\n\n    yes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n53\n38\n2.50\n1.64, 3.82\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe find that there is little evidence for an effect of treatment (HR=0.86 (95% CI 0.57 to 1.28), p=0.45). The assumption is that this effect is constant over the follow-up time period.\nAdjusting for a prognostic factor (bilirubin) which was not evenly distributed between the two treatment arms at baseline we obtain, a treatment HR=0.65 (95% CI 0.43 to 0.99). Further adjustment for presence of cirrhosis at entry into the trial has little effect on the estimated effect of treatment HR= 0.63 (0.42 to 0.96)\nThe underlying assumption is that treatment reduces mortality by about 37% over the entire follow-up period, once the effects of bilirubin and cirrhosis at entry into the trial are taken into account. Time in study (i.e. time since randomisation) would be the appropriate time scale to use as these are data from a randomised controlled trial.",
    "crumbs": [
      "Home",
      "09: Further issues in analysis of cohort studies"
    ]
  },
  {
    "objectID": "ASME_04.html",
    "href": "ASME_04.html",
    "title": "3: Matched case-control studies",
    "section": "",
    "text": "Show the code\n# Data wrangling\n# read \"dta\" files\nlibrary(haven) \n# create table\nlibrary(gtsummary)\n# data wrangling and other functions\nlibrary(tidyverse)\n# if you want to have a output similar to stata\nlibrary(tidylog)\nlibrary(epiDisplay) #some basic tests\n# Limit significant digits to 2, remove scientific notation\nlibrary(survival)\noptions(digits = 2, scipen = 9)\nShow the code\ndiabraz &lt;- read_dta(\"datasets/DIABRAZ.DTA\")\ndiabraz2 &lt;- read_dta(\"datasets/DIABRAZ2.DTA\")\nShow the code\n# * BRAZILIAN CASE-CONTROL STUDY OF RISK FACTORS FOR INFANT DEATH FROM DIARRHOEA\n# * case       1=case, 0=control\n# * milkgp     1=breast only, 2=breast+other, 3=other only\n# * bf         1=breastfed, 2=not breastfed\n# * water      Piped water supply: 1=in house, 2=in plot, 3=none\n# * wat2       1=in house/plot 2=none\n# * agegp      Age group (months): 1=0-1, 2=2-3, 3=4-5, 4=6-8, 5=9-11\n# * agegp2     1=0-2, 2=3-5, 3=6-11\n# * milkgp     1=breast only, 2=breast+other, 3=other only\n# Check the class of each variable\nglimpse(diabraz)\nglimpse(diabraz2)\n# case need to be numeric\ndiabraz2$case &lt;- as.numeric(diabraz2$case)",
    "crumbs": [
      "Home",
      "3: Matched case-control studies"
    ]
  },
  {
    "objectID": "ASME_04.html#mantel-haenszel",
    "href": "ASME_04.html#mantel-haenszel",
    "title": "3: Matched case-control studies",
    "section": "Mantel-Haenszel",
    "text": "Mantel-Haenszel\n\n\nShow the code\ndiabraz |&gt;\n  pubh::mhor(case ~ pair / bf)\n\n\n\n              OR Lower.CI Upper.CI Pr(&gt;|z|)\n(Intercept) 1.11     0.60     2.05    0.740\npair        0.97     0.95     0.99    0.015\npair:bf     1.02     1.01     1.03    0.005\n\n                          Common OR Lower CI Upper CI Pr(&gt;|z|)\nCochran-Mantel-Haenszel:        4.8        2       12  &lt; 0.001\n\nTest for effect modification (interaction): p =  0.65 \n \n\n\nShow the code\n# Other option\n#epiDisplay::mhor(diabraz$case, diabraz$bf, diabraz$pair, graph = F)",
    "crumbs": [
      "Home",
      "3: Matched case-control studies"
    ]
  },
  {
    "objectID": "ASME_04.html#conditional-logistic-regression",
    "href": "ASME_04.html#conditional-logistic-regression",
    "title": "3: Matched case-control studies",
    "section": "Conditional Logistic regression",
    "text": "Conditional Logistic regression\n\nShow the code\nclogit_mod &lt;- clogit(case ~ bf + strata(pair), diabraz)\ntbl_regression(clogit_mod, exponentiate = T)\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nMilk, 2 groups\n4.83\n2.01, 11.6\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio",
    "crumbs": [
      "Home",
      "3: Matched case-control studies"
    ]
  },
  {
    "objectID": "ASME_04.html#unconditional-logistic-regression",
    "href": "ASME_04.html#unconditional-logistic-regression",
    "title": "3: Matched case-control studies",
    "section": "Unconditional Logistic regression",
    "text": "Unconditional Logistic regression\n\nShow the code\nunclogit_mod &lt;- glm(case ~ bf, diabraz, family = binomial)\ntbl_regression(unclogit_mod, exponentiate = T)\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nMilk, 2 groups\n3.00\n1.62, 5.63\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio",
    "crumbs": [
      "Home",
      "3: Matched case-control studies"
    ]
  },
  {
    "objectID": "ASME_11.html",
    "href": "ASME_11.html",
    "title": "11: Cluster randomized trials",
    "section": "",
    "text": "Q1\nYou have been asked to design an (unmatched) cluster-randomised trial to measure the impact of immunisation with a newly developed pneumococcal vaccine on all-cause child mortality in a rural African population. Villages are to be randomly allocated to the intervention or control arms. In the intervention arm, all infants will receive the pneumococcal vaccine in a 3 dose regimen before the age of 6 months, and will then be followed up for two years (to age 30 months) to record mortality. In the control arm, infants will receive a placebo vaccine and will be followed up in the same way.\nCurrent child mortality in the age-range 6-29 months is estimated to be 35 per 1000 child-years, and you estimate that this is likely to vary between 25 and 45 per 1000 child-years in most villages. You wish to have 80% power of detecting a 20% reduction in all-cause mortality due to the pneumococcal vaccine. Each year, around 100 infants reach the age of six months in each village, and you plan to recruit infants to the trial for three years.\nEstimate roughly how many villages you will need to recruit to each arm of the trial. What is the design effect?\n\n\nShow the code\nlibrary(haven) \n# create table\nlibrary(gtsummary)\n# data wrangling and other functions\nlibrary(tidyverse)\n# if you want to have a output similar to stata\nlibrary(tidylog)\n#cox\nlibrary(survival)\n\n# Limit significant digits to 3, remove scientific notation\noptions(digits = 3, scipen = 9)\n\n\n\n\nShow the code\nt &lt;- 3\nm &lt;- 100\ng &lt;- 2\nlc &lt;- 0.035\nle &lt;- 0.035*0.8\nalpha &lt;- 0.05\npower &lt;- 0.8\nCV &lt;-  0.14\n       T &lt;- t * m  * g\n        IFt &lt;- ((lc +le)/ T + (CV^2) * (lc^2 + le^2))\n        f &lt;- (qnorm(1 - alpha/2) + qnorm(power))^2\n        sample &lt;- (IFt * f)/(lc - le)^2  +1\n\n\n\n\nQ2\nThis question uses data from the Gambian National Impregnated Bednet Programme, datasets GAMINDIV.DTA and GAMVILL.DTA. The data are from a cross-sectional survey of children aged 1-4 years conducted at the end of the transmission season in a sample of villages from each treatment arm. See course manual for further details.\n\n\nShow the code\ndt_cluster &lt;- read_dta(\"datasets/GAMVILL.DTA\") |&gt; \n  mutate(across(where(is.labelled),as_factor))\n\ndt_ind &lt;- read_dta(\"datasets/GAMINDIV.DTA\") |&gt; \n  mutate(across(where(is.labelled),as_factor))\n\n\nUsing GAMVILL.DTA, look at histograms of village parasite prevalence by treatment arm. Is there any apparent difference?\nVariables that we will use:\n**Outcome*: - in individual dataset: para (malaria status: 1 = positive, 2 = negative) - in summary dayaset: parapos (number of children positive), paraneg (number of children negative), rate (village parasite prevalence: parapos/(parapos+paraneg)) **Exposure*: group (treatment arm: 1 = bednets, 2 = control) **Cluster*: vid (village)\n\n\nShow the code\ndt_cluster |&gt; \n  mutate(group = if_else(group==1,\"Bednets\",\"Control\")) |&gt; \nggplot() +\n  geom_histogram(aes(rate,fill=group), binwidth = 0.1, color=\"white\")+\n  scale_y_continuous(breaks = seq(0:10))\n\n\n\n\n\n\n\n\n\nEstimate the overall parasite prevalence for each group: (i) by summing over all children (GAMINDIV.DTA); and (ii) by averaging village prevalences (GAMVILL.DTA). Is there any difference between these two estimates?\n\n\nShow the code\ndt_ind |&gt; count(para) |&gt; \n  mutate(perc = prop.table(n))\n\n\n\n\n\n\npara\nn\nperc\n\n\n\n\n1\n385\n0.33\n\n\n2\n781\n0.67\n\n\n\n\n\n\nShow the code\ndt_cluster |&gt; summarise(prev = mean(rate))\n\n\n\n\n\n\nprev\n\n\n\n\n0.335\n\n\n\n\n\n\nTest the hypothesis that net impregnation reduces the prevalence of malaria parasites using the standard chi-squared test, ignoring the randomisation by village (use GAMINDIV.DTA).\n\n\nShow the code\ntab1 &lt;- table(dt_ind$para, dt_ind$group) \nchisq.test(tab1)\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tab1\nX-squared = 6, df = 1, p-value = 0.01\n\n\nTest the same null hypothesis, but allowing for randomisation by village, by using (i) a t-test on village prevalences; (ii) a Wilcoxon rank sum test on village prevalences.\n\n\nShow the code\nt.test(rate~group, data=dt_cluster,\n       var.equal = T)\n\n\n\n    Two Sample t-test\n\ndata:  rate by group\nt = -2, df = 32, p-value = 0.06\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -0.23729  0.00673\nsample estimates:\nmean in group 1 mean in group 2 \n          0.277           0.392 \n\n\nShow the code\nwilcox.test(rate~group, data=dt_cluster,\n            correct=F)\n\n\n\n    Wilcoxon rank sum test\n\ndata:  rate by group\nW = 96, p-value = 0.09\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nThe default value for t.test in R is considering unequal variances (while in stata is considering equal variances), that’s why we need to include “var.equal=T” to get the same answers. Similarly, for the Wilcoxon, by default it applies a continuity correction in the normal approximation for the p-value (not by default in stata)\n\n\n\nCompare the results you obtain from (d) with your unadjusted result from (c). How does the adjustment for clustering change your interpretation of the effect of bednet impregnation on parasite status?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe standard \\(\\chi^2\\) test shows a highly significant effect of treatment, and is invalid! The other tests, which allow for the clustered design, give larger P-values indicating only weak evidence that the treatment has an effect on parasite status.\n\n\n\n\nOPTIONAL: Obtain a 95% confidence interval for the ratio of parasite prevalence in the intervention and control arms.\n\n\n\nShow the code\n#get the risks\n# dt_ind |&gt; group_by(group) |&gt; \n#   count(para) |&gt; \n#   mutate(risk=n/sum(n)) |&gt; \n#   filter(para==1) |&gt; \n#   ungroup() |&gt; \n#   mutate(rr = risk[group==\"1\"]/risk[group==\"2\"])\n\n# Risk in each arm\nr0 &lt;- 0.367\nr1 &lt;- 0.298\n\n# Risk ratio \nRR &lt;- r1/r0\nlogRR &lt;- log(RR)\n\n# Standard deviations of rates in each group (by cluster )\n#dt_cluster |&gt; group_by(group) |&gt; summarise(sd(rate)) - get the SD \ns1 &lt;- 0.15\ns0 &lt;- 0.196\n\n# Numbers of clusters\nc1 &lt;- 17\nc0 &lt;- 17\n\n# Variances of risks\nvar_r1 &lt;- (s1^2)/c1\nvar_r0 &lt;- (s0^2)/c0\n\n# Variance of the log RR\nvar_logRR &lt;- var_r1/(r1^2) + var_r0/(r0^2)\n\n# Confidence intervals\nlower_CI &lt;- exp(logRR - 1.96 * sqrt(var_logRR))\nupper_CI &lt;- exp(logRR + 1.96 * sqrt(var_logRR))\n\ndata.frame(rr= RR, lcl = lower_CI, ucl =  upper_CI)\n\n\n\n\n\n\nrr\nlcl\nucl\n\n\n\n\n0.812\n0.573\n1.15\n\n\n\n\n\n\n\nUsing GAMINDIV.DTA, reanalyse the data from this trial using GEE and random effects logistic regression. How do your results compare with those from (d)?\n\n\n\nShow the code\nlibrary(geepack)\nlibrary(lme4)\ndt_ind &lt;- dt_ind |&gt; \n  mutate(para_bin = (if_else(para==1,1,0)),\n         vid_fac = as.factor(vid),\n         group_bin = as.factor(if_else(group==2,0,1))) \n  \ndt_ind_order &lt;- dt_ind |&gt; \n  arrange(vid_fac) # geeglm (geepack) assumes that the observations from the same cluster appears contiguous\nmod_unorder &lt;- geeglm(para_bin~group_bin,\n       id = vid_fac,\n       data=dt_ind,\n       corstr = \"exchangeable\",\n       family = binomial(link=\"logit\"))\n\nmod_order &lt;- geeglm(para_bin~group_bin,\n       id = vid_fac,\n       data=(dt_ind_order),\n       corstr = \"exchangeable\",\n       family = binomial(link=\"logit\"))\n#broom::tidy(mod_unorder, exponentiate=T) #check that it gives the wrong answer\nbroom::tidy(mod_order, exponentiate = T) |&gt; gt::gt()\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.635\n0.196\n5.37\n0.0205\n\n\ngroup_bin1\n0.610\n0.264\n3.50\n0.0614\n\n\n\n\n\n\n\n\n\nShow the code\n# geeM doesnt require ordering\n# mod &lt;- geeM::geem(para_bin~group_bin,\n#        id = vid_fac,\n#        data=as.data.frame(dt_ind),\n#        corstr = \"exchangeable\",\n#        family = binomial(link=\"logit\"))\n# summary(mod)\n\nmod &lt;- glmer(para_bin~group_bin + (1|vid),\n       data=dt_ind,\n       family = \"binomial\")\nbroom.mixed::tidy(mod, exponentiate=T, effects=\"fixed\") |&gt; gt::gt()\n\n\n\n\n\n\n\n\neffect\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\nfixed\n(Intercept)\n0.593\n0.124\n-2.50\n0.0124\n\n\nfixed\ngroup_bin1\n0.584\n0.174\n-1.81\n0.0705\n\n\n\n\n\n\n\n\n\nQ3\nDataset MZTRIAL.DTA contains individual-level data from the Mwanza trial of the impact of improved STD treatment services on HIV incidence. There were 12 communities in 6 matched pairs, and a random cohort of around 1000 adults aged 15-54 years was followed up in each community. The dataset contains data on HIV seroconversion among those individuals who were seronegative at baseline and who were successfully followed up after two years. We are going to analyse the results of the trial with and without adjustment for confounding variables (see Section 6).\n\n\nShow the code\ndt_mzt &lt;- read_dta(\"datasets/MZTRIAL.DTA\") |&gt; \n  mutate(across(where(is.labelled),as_factor))\n\ndt_mzt &lt;- dt_mzt  |&gt;  mutate(arm = factor(arm,\n                            levels = c(0, 1),\n                            labels = c(\"control\", \"intervention\")),\n              comp = factor(comp),\n              pair = factor(pair),\n              agegp = factor(agegp,\n                             levels = 1:4,\n                             labels = c(\"15-24\", \"25-34\", \"35-44\", \"45-54\")),\n              sex = factor(sex,\n                           levels = c(1, 2),\n                           labels = c(\"male\", \"female\")))\n\n\n\nUsing the following commands, first use logistic regression to adjust the results for possible confounding variables, including age, sex, matched pair and the baseline HIV prevalence in each community:\n\nmodel = glm(hiv ~ agegp + sex + pair + hivbase) predict(model, type=\"response\")\n\n\nShow the code\nmod_hiv_prob &lt;- glm(hiv ~ agegp + sex + pair + hivbase,\n                    family = binomial,\n                    data = dt_mzt)\ndt_mzt$fitted_hiv_prob &lt;- predict(mod_hiv_prob, type = \"response\")\n\n\n\n\nShow the code\ndt_mzt |&gt; \n  ggplot(aes(fitted_hiv_prob))+\n  geom_histogram(aes(fill=arm))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nThe predict takes a model and give the prediction using a new dataset. In the case of no “newdata” being declared, it will use the dataset used for fitting the model. The type=\"response\" is related to give the prediction in the response scale, i.e., in the probability scale\n\n\n\n\nNow use collapse to sum up the observed and fitted values for each of the 12 communities:\n\n\n\nShow the code\ndt_mzt|&gt; group_by(pair, comp, arm) %&gt;%\n  summarise(\"observed\" = sum(hiv),\n            \"at_risk\" = n(),\n            \"expected\" = sum(fitted_hiv_prob))\n\n\n\n\n\n\npair\ncomp\narm\nobserved\nat_risk\nexpected\n\n\n\n\n1\n1\nintervention\n5\n568\n7.16\n\n\n1\n2\ncontrol\n10\n702\n7.84\n\n\n2\n3\nintervention\n4\n766\n5.34\n\n\n2\n4\ncontrol\n7\n833\n5.66\n\n\n3\n5\nintervention\n17\n650\n16.66\n\n\n3\n6\ncontrol\n20\n630\n20.34\n\n\n4\n7\nintervention\n13\n734\n18.77\n\n\n4\n8\ncontrol\n23\n760\n17.23\n\n\n5\n9\nintervention\n4\n732\n6.89\n\n\n5\n10\ncontrol\n12\n782\n9.11\n\n\n6\n11\nintervention\n5\n699\n6.46\n\n\n6\n12\ncontrol\n10\n693\n8.54\n\n\n\n\n\n\n\nUnadjusted analysis: Compute the unadjusted RR for each matched pair (obtained using hiv and n from (b)). Carry out a paired t-test on the log(RR). Using the mean of the log(RR), find the geometric mean (remember: t test of the log-transformed data is a test of differences between geometric means) of the RR over all matched pairs, and obtain a 95% confidence interval for this. Adjusted analysis: Repeat the above calculations on the adjusted RR for each matched pair (obtained using hiv and fv from (b)).\n\n\n\nShow the code\ndd_unaj &lt;- dt_mzt|&gt; group_by(pair, comp, arm) %&gt;%\n  summarise(\"observed\" = sum(hiv),\n            \"at_risk\" = n(),\n            \"expected\" = sum(fitted_hiv_prob)) |&gt; \n  group_by(pair) |&gt; \n  mutate(rr = observed[arm==\"intervention\"]/at_risk[arm==\"intervention\"]/(observed[arm==\"control\"]/at_risk[arm==\"control\"])) |&gt;\n  filter(arm==\"intervention\") |&gt; \n  select(pair, rr)\ndd_adj &lt;- dt_mzt|&gt; group_by(pair, comp, arm) %&gt;%\n  summarise(\"observed\" = sum(hiv),\n            \"at_risk\" = n(),\n            \"expected\" = sum(fitted_hiv_prob)) |&gt; \n  group_by(pair) |&gt; \n  mutate(adjrr = observed[arm==\"intervention\"]/expected[arm==\"intervention\"]/(observed[arm==\"control\"]/expected[arm==\"control\"])) |&gt;\n  filter(arm==\"intervention\") |&gt; \n  select(pair, adjrr)\ndd_unaj |&gt; \n  left_join(dd_adj, by = \"pair\")\n\n\n\n\n\n\npair\nrr\nadjrr\n\n\n\n\n1\n0.618\n0.548\n\n\n2\n0.621\n0.606\n\n\n3\n0.824\n1.038\n\n\n4\n0.585\n0.519\n\n\n5\n0.356\n0.441\n\n\n6\n0.496\n0.661\n\n\n\n\n\n\nCalculated the paired t-tests in R\nUnadjusted\n\n\nShow the code\ndd_unadj_test &lt;- dt_mzt|&gt; group_by(pair, comp, arm) %&gt;%\n  summarise(\"observed\" = sum(hiv),\n            \"at_risk\" = n(),\n            \"expected\" = sum(fitted_hiv_prob)) |&gt; \n  group_by(pair) |&gt; \n  mutate(logrr = log(observed/at_risk))\nt_test_values&lt;- t.test(dd_unadj_test[dd_unadj_test$arm==\"intervention\",]$logrr,dd_unadj_test[dd_unadj_test$arm==\"control\",]$logrr,paired=T)\nt_test_values\n\n\n\n    Paired t-test\n\ndata:  dd_unadj_test[dd_unadj_test$arm == \"intervention\", ]$logrr and dd_unadj_test[dd_unadj_test$arm == \"control\", ]$logrr\nt = -5, df = 5, p-value = 0.004\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.864 -0.277\nsample estimates:\nmean difference \n          -0.57 \n\n\nShow the code\ndata.frame(estimate = exp(t_test_values$estimate), #need to back transform \n           lcl = exp(t_test_values$conf.int[1]),\n           ucl = exp(t_test_values$conf.int[2]))\n\n\n\n\n\n\n\nestimate\nlcl\nucl\n\n\n\n\nmean difference\n0.565\n0.422\n0.758\n\n\n\n\n\n\nAdjusted\n\n\nShow the code\ndd_adj_test &lt;- dt_mzt|&gt; group_by(pair, comp, arm) %&gt;%\n  summarise(\"observed\" = sum(hiv),\n            \"at_risk\" = n(),\n            \"expected\" = sum(fitted_hiv_prob)) |&gt; \n  group_by(pair) |&gt; \n  mutate(logadjrr = log(observed/expected))\n\nt_test_values&lt;- t.test(dd_adj_test[dd_adj_test$arm==\"intervention\",]$logadjrr,dd_adj_test[dd_adj_test$arm==\"control\",]$logadjrr,paired=T)\nt_test_values\n\n\n\n    Paired t-test\n\ndata:  dd_adj_test[dd_adj_test$arm == \"intervention\", ]$logadjrr and dd_adj_test[dd_adj_test$arm == \"control\", ]$logadjrr\nt = -4, df = 5, p-value = 0.009\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.801 -0.184\nsample estimates:\nmean difference \n         -0.492 \n\n\nShow the code\ndata.frame(estimate = exp(t_test_values$estimate),\n           lcl = exp(t_test_values$conf.int[1]),\n           ucl = exp(t_test_values$conf.int[2]))\n\n\n\n\n\n\n\nestimate\nlcl\nucl\n\n\n\n\nmean difference\n0.611\n0.449\n0.832",
    "crumbs": [
      "11: Cluster randomized trials"
    ]
  },
  {
    "objectID": "ASME_12.html",
    "href": "ASME_12.html",
    "title": "12: Missing data",
    "section": "",
    "text": "Incomplete solutions (only question 1.2 and 1.3)\nShow the code\nlibrary(haven) \n# create table\nlibrary(gtsummary)\n# data wrangling and other functions\nlibrary(tidyverse)\n# if you want to have a output similar to stata\nlibrary(tidylog)\n#imputation\nlibrary(mice)\n\n# Limit significant digits to 4, remove scientific notation (most of the time, scipen=999 removes all time)\noptions(digits = 4, scipen = 9)",
    "crumbs": [
      "12: Missing data"
    ]
  },
  {
    "objectID": "ASME_12.html#how-many-observations-are-used-in-the-complete-case-analysis",
    "href": "ASME_12.html#how-many-observations-are-used-in-the-complete-case-analysis",
    "title": "12: Missing data",
    "section": "How many observations are used in the complete case analysis?",
    "text": "How many observations are used in the complete case analysis?\n\n\nShow the code\nno_obs &lt;- melb |&gt; \n  drop_na(noqual2,\n          care,\n          soch7,\n          invbwt,\n          mo_age) |&gt; \n  nrow()\nmelb &lt;- melb |&gt; \n    mutate(\n    care = as.factor(care),\n    soch7 = as.factor(soch7),\n    noqual2 = as.factor(noqual2),\n    invbwt = as.numeric(invbwt)\n  )\ncomplete_case_model &lt;- glm(noqual2~ care + soch7 +invbwt+ mo_age, family=\"binomial\",\n                           data=melb)\ntbl_complete &lt;- tbl_regression(complete_case_model,\n               estimate_fun = purrr::partial(style_ratio, digits = 3)) |&gt; \n  modify_column_unhide(column = std.error)\ntbl_complete\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nlog(OR)\nSE\n95% CI\np-value\n\n\n\n\ncare\n\n\n\n\n\n\n\n\n\n\n    0\n—\n—\n—\n\n\n\n\n    1\n1.093\n0.157\n0.788, 1.402\n&lt;0.001\n\n\nsoch7\n\n\n\n\n\n\n\n\n\n\n    0\n—\n—\n—\n\n\n\n\n    1\n0.947\n0.046\n0.858, 1.037\n&lt;0.001\n\n\ninvbwt\n123.9\n14.2\n96.23, 151.7\n&lt;0.001\n\n\nmother's age at birth (centered around 28)\n-0.007\n0.004\n-0.015, 0.001\n0.10\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio, SE = Standard Error\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is no_obs observations in complete case analysis",
    "crumbs": [
      "12: Missing data"
    ]
  },
  {
    "objectID": "ASME_12.html#what-percentage-of-records-are-incomplete",
    "href": "ASME_12.html#what-percentage-of-records-are-incomplete",
    "title": "12: Missing data",
    "section": "What percentage of records are incomplete?",
    "text": "What percentage of records are incomplete?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is no_obs/nrow(melb) observations are incomplete\n\n\n\nUnder what assumption would inference from the complete records be valid? Do you believe this assumption?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe probability of a complete record is not associated with qualification status, given the covariates in the model. This may be plausible, since qualification status is observed at age 23. However, it is also possible that having data at age 23 may be related to educational qualifications, for example people with educational qualifications may be more likely to move away from home and drop out of the study.",
    "crumbs": [
      "12: Missing data"
    ]
  },
  {
    "objectID": "ASME_12.html#use-observed-data-to-investigate-this-assumption.-does-the-assumption-hold",
    "href": "ASME_12.html#use-observed-data-to-investigate-this-assumption.-does-the-assumption-hold",
    "title": "12: Missing data",
    "section": "Use observed data to investigate this assumption. Does the assumption hold?",
    "text": "Use observed data to investigate this assumption. Does the assumption hold?\n\n\nShow the code\n# Select the variables you want to impute/missing info (algo including the outcome even if there is no missing in the outcome)\ndata.to.impute&lt;- melb |&gt; \n  select(\n    noqual2,\n          care,\n          soch7,\n          invbwt,\n          mo_age\n  )\nmd.pattern(data.to.impute, plot = T, rotate.names = T)\n\n\n\n\n\n\n\n\n\n      mo_age invbwt care soch7 noqual2      \n10279      1      1    1     1       1     0\n3324       1      1    1     1       0     1\n59         1      1    1     0       1     1\n64         1      1    1     0       0     2\n3          1      1    0     1       1     1\n1          1      1    0     1       0     2\n1153       1      1    0     0       1     2\n1886       1      1    0     0       0     3\n349        1      0    1     1       1     1\n116        1      0    1     1       0     2\n3          1      0    1     0       1     2\n3          1      0    1     0       0     3\n1          1      0    0     1       1     2\n37         1      0    0     0       1     3\n124        1      0    0     0       0     4\n6          0      1    1     1       1     1\n7          0      1    1     1       0     2\n1          0      1    0     0       0     4\n109        0      0    1     1       1     2\n37         0      0    1     1       0     3\n1          0      0    1     0       1     3\n3          0      0    1     0       0     4\n44         0      0    0     0       1     4\n21         0      0    0     0       0     5\n         229    848 3271  3399    5587 13334\n\n\nShow the code\ndt_indicator &lt;- data.to.impute |&gt; \n  mutate(\n    complete_case = if_else(\n      !is.na(noqual2) &\n        !is.na(soch7) &\n      !is.na(invbwt) &\n        !is.na(mo_age)&\n      !is.na(care),\n      0,\n      1\n    )\n  )\nmod_ind &lt;- glm(complete_case ~ noqual2 + invbwt+mo_age, family = binomial, data=dt_indicator)\n\ntbl_regression(mod_ind)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nlog(OR)\n95% CI\np-value\n\n\n\n\nnoqual2\n\n\n\n\n\n\n\n\n    0\n—\n—\n\n\n\n\n    1\n0.17\n0.04, 0.30\n0.008\n\n\ninvbwt\n32\n-4.5, 68\n0.081\n\n\nmother's age at birth (centered around 28)\n-0.02\n-0.03, -0.01\n0.002\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio",
    "crumbs": [
      "12: Missing data"
    ]
  },
  {
    "objectID": "ASME_12.html#can-we-determine-the-missingness-mechanism-from-the-dataset",
    "href": "ASME_12.html#can-we-determine-the-missingness-mechanism-from-the-dataset",
    "title": "12: Missing data",
    "section": "Can we determine the missingness mechanism from the dataset?",
    "text": "Can we determine the missingness mechanism from the dataset?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nNo, we have found evidence that missingness is associated with a number of the other variables in the dataset. We therefore have evidence against Missing Completely at Random (MCAR). However, we cannot from the observed data determine whether the values are Missing at Random (MAR) or Missing Not at Random (MNAR).\nTake note this regression is only taking into account the observations with non-missing in the variables included",
    "crumbs": [
      "12: Missing data"
    ]
  },
  {
    "objectID": "ASME_12.html#solution",
    "href": "ASME_12.html#solution",
    "title": "12: Missing data",
    "section": "Solution",
    "text": "Solution\nThe probably reason of it not running is because the low variability of that variable, we can keep it but lets multiple by 100.\n\n\nShow the code\ndata.to.impute&lt;- melb |&gt; \n  select(\n    noqual2,\n          care,\n          soch7,\n          invbwt,\n          mo_age\n  ) |&gt; \n  mutate(\n    invbwt_100 = 100*invbwt\n  ) |&gt; \n  select(-invbwt) #remove original because collinear\n\n# Run a dry imp (no iteration) to get a predction matrix\nimp &lt;- mice(data.to.impute, maxit=0)\n\n# Extract predictorMatrix and methods of imputation \n\npredM &lt;- imp$predictorMatrix\nmeth &lt;- imp$method\n\n# We will need to say to only use invbwt_100 in the imputation\n\nmeth[\"mo_age\"] &lt;- \"norm\" #linear regression\nmeth[\"invbwt_100\"] &lt;- \"norm\" #linear regression\n#  solution run 10 iterations and 15 datasets - usually you can get good results with 5 and 10 datasets and iterations (but it depends!)\n# you can reduce it to save computation time (in your practical)\nimp2 &lt;- mice(data.to.impute, maxit = 10,  # equivalent to \"burn\"\n             m= 15, #number of datasets\n             predictorMatrix = predM, \n             method = meth, print =  F,\n             seed = 123)\n\n\n\n\nShow the code\n#Then fit the model to each imputed data set:\ncomplete_case_model &lt;- glm(noqual2~ care + soch7 +invbwt_100+ mo_age, family=\"binomial\",\n                           data=data.to.impute)\ntbl_complete &lt;- tbl_regression(complete_case_model,\n               estimate_fun = purrr::partial(style_ratio, digits = 3)) |&gt; \n  modify_column_unhide(column = std.error)\n\nfit.ncds&lt;-with(data=imp2,exp=glm(noqual2~ care + soch7 +invbwt_100+ mo_age, family=\"binomial\"))\n#summary(pool(fit.ncds))\ntbl_imp &lt;- tbl_regression(fit.ncds, estimate_fun = purrr::partial(style_ratio, digits = 3))|&gt; \n  modify_column_unhide(column = std.error)\n\ntbl_merge(\n  list(tbl_complete, tbl_imp),\n  tab_spanner = c(\"**Complete Case**\",\"**Imputation**\")\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nComplete Case\n\n\nImputation\n\n\n\nlog(OR)\nSE\n95% CI\np-value\nlog(OR)\nSE\n95% CI\np-value\n\n\n\n\ncare\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    0\n—\n—\n—\n\n\n—\n—\n—\n\n\n\n\n    1\n1.093\n0.157\n0.788, 1.402\n&lt;0.001\n1.092\n0.140\n0.813, 1.371\n&lt;0.001\n\n\nsoch7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    0\n—\n—\n—\n\n\n—\n—\n—\n\n\n\n\n    1\n0.947\n0.046\n0.858, 1.037\n&lt;0.001\n0.947\n0.045\n0.857, 1.037\n&lt;0.001\n\n\ninvbwt_100\n1.239\n0.142\n0.962, 1.517\n&lt;0.001\n1.173\n0.127\n0.916, 1.429\n&lt;0.001\n\n\nmother's age at birth (centered around 28)\n-0.007\n0.004\n-0.015, 0.001\n0.10\n-0.007\n0.004\n-0.015, 0.001\n0.075\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio, SE = Standard Error",
    "crumbs": [
      "12: Missing data"
    ]
  },
  {
    "objectID": "ASME_02.html",
    "href": "ASME_02.html",
    "title": "2: Review of Logistic Regression",
    "section": "",
    "text": "All code solutions are hidden by default, you can see the underlying code clicking in “Show the code”",
    "crumbs": [
      "Home",
      "2: Review of Logistic Regression"
    ]
  },
  {
    "objectID": "ASME_02.html#a",
    "href": "ASME_02.html#a",
    "title": "2: Review of Logistic Regression",
    "section": "2a",
    "text": "2a\n\nObtain a frequency table of npa. What is the most commonly occurring number of lifetime sexual partners? Where npa is missing (9) recode to STATA’s own missing value code (.) using the command mvdecode or recode. Form a cross-tabulation of number of lifetime sexual partners with HIV status.\n\n\n\nShow the code\nmwanza |&gt; tbl_summary(include = c(npa))\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 7631\n\n\n\n\nnpa\n\n\n\n\n    1\n200 (27%)\n\n\n    2\n369 (50%)\n\n\n    3\n123 (17%)\n\n\n    4\n43 (5.9%)\n\n\n    Unknown\n28\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\nWhat is the most common number of lifetime sexual partners?\nCross-tabulate number of lifetime sexual partners with HIV status.\n\n\nShow the code\nmwanza |&gt; tbl_summary(include = c(npa), by = case)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n0 N = 5741\n1 N = 1891\n\n\n\n\nnpa\n\n\n\n\n\n\n    1\n173 (31%)\n27 (15%)\n\n\n    2\n277 (50%)\n92 (50%)\n\n\n    3\n83 (15%)\n40 (22%)\n\n\n    4\n19 (3.4%)\n24 (13%)\n\n\n    Unknown\n22\n6\n\n\n\n1 n (%)",
    "crumbs": [
      "Home",
      "2: Review of Logistic Regression"
    ]
  },
  {
    "objectID": "ASME_02.html#b",
    "href": "ASME_02.html#b",
    "title": "2: Review of Logistic Regression",
    "section": "2b",
    "text": "2b\n\nFit a logistic model to estimate the strength of association between npa and HIV status, treating npa as a factor. Is there evidence for an association between npa and HIV? What do you conclude?\n\n\n\nShow the code\nglm(case ~ npa,\n    family = binomial,\n    data = mwanza) |&gt; \n  tbl_regression(exponentiate = T) |&gt; \n  add_global_p(keep=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nnpa\n\n\n\n\n&lt;0.001\n\n\n    1\n—\n—\n\n\n\n\n    2\n2.13\n1.35, 3.46\n0.002\n\n\n    3\n3.09\n1.78, 5.42\n&lt;0.001\n\n\n    4\n8.09\n3.95, 17.0\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\nIs there evidence of association?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is strong evidence of an association between the number of lifetime partners and being HIV positive.",
    "crumbs": [
      "Home",
      "2: Review of Logistic Regression"
    ]
  },
  {
    "objectID": "ASME_02.html#c",
    "href": "ASME_02.html#c",
    "title": "2: Review of Logistic Regression",
    "section": "2c",
    "text": "2c\nA more convenient way to fit this model is to use the most prevalent group as a baseline. Which group was used in (b)? Why does it make sense to use the most prevalent group as baseline? Refit the model using the most prevalent group as baseline.\n\n\nShow the code\n# Relevel the factor\nmwanza &lt;- mwanza |&gt; \n  # the first argument of fct_relevel is the variable and the second argument the level you \n  # want to be the reference level\n  mutate(npa = fct_relevel(npa,\"2\")) \n\n# Logistic regression (unchanged)\nglm(case ~ npa,\n    family = binomial,\n    data = mwanza) |&gt; \n  tbl_regression(exponentiate = T) |&gt; \n  add_global_p(keep=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nnpa\n\n\n\n\n&lt;0.001\n\n\n    2\n—\n—\n\n\n\n\n    1\n0.47\n0.29, 0.74\n0.002\n\n\n    3\n1.45\n0.92, 2.26\n0.10\n\n\n    4\n3.80\n2.00, 7.34\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf we use the most prevalent group as the baseline, then the SEs for the \\(\\beta\\)s (log(OR)) will be smaller.",
    "crumbs": [
      "Home",
      "2: Review of Logistic Regression"
    ]
  },
  {
    "objectID": "ASME_02.html#d",
    "href": "ASME_02.html#d",
    "title": "2: Review of Logistic Regression",
    "section": "2d",
    "text": "2d\nAmend your model to control for the confounding effect of age treated as a factor (age1).\n\n\nShow the code\nglm(case ~ npa + age1,\n    family = binomial,\n    data = mwanza) |&gt; \n  tbl_regression(exponentiate = T) |&gt; \n  add_global_p(keep=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nnpa\n\n\n\n\n&lt;0.001\n\n\n    2\n—\n—\n\n\n\n\n    1\n0.51\n0.31, 0.81\n0.006\n\n\n    3\n1.30\n0.82, 2.04\n0.3\n\n\n    4\n4.75\n2.43, 9.47\n&lt;0.001\n\n\nage1\n\n\n\n\n&lt;0.001\n\n\n    1\n—\n—\n\n\n\n\n    2\n3.27\n1.69, 6.69\n&lt;0.001\n\n\n    3\n2.50\n1.24, 5.28\n0.013\n\n\n    4\n1.93\n0.93, 4.15\n0.082\n\n\n    5\n1.26\n0.61, 2.73\n0.5\n\n\n    6\n0.81\n0.35, 1.87\n0.6\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\nShow the code\n# if you want to see the more details about the overall signficance of each variable\n# anova(glm(case ~ npa + age1,\n#     family = binomial,\n#     data = mwanza))\n\n\nWhat is your conclusion?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAdding age1 to the model changes the odds ratios for npa (0.51, 1.30, 4.75) showing the confounding effect of age. After adjusting for age, there is strong evidence that npa is associated with being a case (LRT gives X32=35.44, p&lt;0.001).",
    "crumbs": [
      "Home",
      "2: Review of Logistic Regression"
    ]
  },
  {
    "objectID": "ASME_02.html#e.-summary-table",
    "href": "ASME_02.html#e.-summary-table",
    "title": "2: Review of Logistic Regression",
    "section": "2e. Summary table",
    "text": "2e. Summary table\nSummarise the results of the analyses conducted above in a table - show the distribution of number of partners in cases and controls, odds ratios (unadjusted and age-adjusted effect of number of lifetime partners in a table), 95% CIs, p-values.\n\n\nShow the code\n# you can do all three itens in almost one line of code (in R)\n\nlibrary(finalfit)\n\nexplanatory = c(\"npa\", \"age1\")\ndependent = \"case\"\nmwanza |&gt; \n    finalfit(dependent, explanatory) -&gt; table1\nknitr::kable(table1, row.names=FALSE, align=c(\"l\", \"l\", \"r\", \"r\", \"r\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nDependent: case\n\n0\n1\nOR (univariable)\nOR (multivariable)\n\n\n\n\nnpa\n2\n277 (75.1)\n92 (24.9)\n-\n-\n\n\n\n1\n173 (86.5)\n27 (13.5)\n0.47 (0.29-0.74, p=0.002)\n0.51 (0.31-0.81, p=0.006)\n\n\n\n3\n83 (67.5)\n40 (32.5)\n1.45 (0.92-2.26, p=0.101)\n1.30 (0.82-2.04, p=0.264)\n\n\n\n4\n19 (44.2)\n24 (55.8)\n3.80 (2.00-7.34, p&lt;0.001)\n4.75 (2.43-9.47, p&lt;0.001)\n\n\nage1\n1\n96 (88.1)\n13 (11.9)\n-\n-\n\n\n\n2\n108 (65.5)\n57 (34.5)\n3.90 (2.07-7.84, p&lt;0.001)\n3.27 (1.69-6.69, p=0.001)\n\n\n\n3\n84 (68.3)\n39 (31.7)\n3.43 (1.75-7.08, p&lt;0.001)\n2.50 (1.24-5.28, p=0.013)\n\n\n\n4\n85 (72.0)\n33 (28.0)\n2.87 (1.45-5.98, p=0.003)\n1.93 (0.93-4.15, p=0.082)\n\n\n\n5\n107 (78.1)\n30 (21.9)\n2.07 (1.04-4.32, p=0.044)\n1.26 (0.61-2.73, p=0.539)\n\n\n\n6\n94 (84.7)\n17 (15.3)\n1.34 (0.62-2.95, p=0.465)\n0.81 (0.35-1.87, p=0.612)",
    "crumbs": [
      "Home",
      "2: Review of Logistic Regression"
    ]
  },
  {
    "objectID": "ASME_02.html#a-1",
    "href": "ASME_02.html#a-1",
    "title": "2: Review of Logistic Regression",
    "section": "3a",
    "text": "3a\nThe risk of HIV associated with npa is confounded by attending school (using ed2)\n\n\nShow the code\nglm(case ~ npa + age1 + ed2,\n    family = binomial,\n    data = mwanza) |&gt; \n  tbl_regression(exponentiate = T) |&gt; \n  add_global_p(keep=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nnpa\n\n\n\n\n&lt;0.001\n\n\n    2\n—\n—\n\n\n\n\n    1\n0.50\n0.30, 0.81\n0.006\n\n\n    3\n1.24\n0.78, 1.96\n0.4\n\n\n    4\n4.38\n2.22, 8.82\n&lt;0.001\n\n\nage1\n\n\n\n\n0.003\n\n\n    1\n—\n—\n\n\n\n\n    2\n3.20\n1.66, 6.56\n&lt;0.001\n\n\n    3\n2.62\n1.30, 5.56\n0.009\n\n\n    4\n2.28\n1.09, 4.97\n0.031\n\n\n    5\n1.59\n0.75, 3.49\n0.2\n\n\n    6\n1.26\n0.52, 3.06\n0.6\n\n\ned2\n\n\n\n\n0.001\n\n\n    0\n—\n—\n\n\n\n\n    1\n1.97\n1.30, 3.04\n0.002\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nEducational status does not appear to be a strong confounder of the relationship between npa and HIV-infection, after adjusting for age1 as the adjusted ORs are 0.50, 1.24, and 4.38, in similar to the adjusted ORs reported in 2",
    "crumbs": [
      "Home",
      "2: Review of Logistic Regression"
    ]
  },
  {
    "objectID": "ASME_02.html#b.",
    "href": "ASME_02.html#b.",
    "title": "2: Review of Logistic Regression",
    "section": "3b.",
    "text": "3b.\nThere is any evidence the risk of HIV associated with npa differs according to whether the women had attended school.\n\n\nShow the code\n# Model with interaction\nlogit_inter &lt;- glm(case ~ npa * ed2 + age1,\n    family = binomial,\n    data = mwanza)\n\n# Model without interaction\nlogit_without &lt;- glm(case ~ npa + ed2 + age1,\n    family = binomial,\n    data = mwanza)\n\n# Likelihood ratio test\nlmtest::lrtest(logit_without, logit_inter)\n\n\n\n\n\n\n#Df\nLogLik\nDf\nChisq\nPr(&gt;Chisq)\n\n\n\n\n10\n-374\nNA\nNA\nNA\n\n\n13\n-373\n3\n0.5\n0.92\n\n\n\n\n\n\nShow the code\n# Note that ANOVA gives you the same χ statistic and df\n#anova(logit_without, logit_inter)\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nLRT gives \\(\\chi_{3}^2\\)=0.50, p=0.92 suggesting data are compatible with no interaction between lifetime partners and educational status on HIV status.",
    "crumbs": [
      "Home",
      "2: Review of Logistic Regression"
    ]
  },
  {
    "objectID": "ASME_02.html#a-2",
    "href": "ASME_02.html#a-2",
    "title": "2: Review of Logistic Regression",
    "section": "4a",
    "text": "4a\nFit a model including npa, age1 and their interaction, all terms treated as categorical variables.\n\nWhat happens when you carry out a LR test of the interaction term?\n\n\n\nShow the code\n# You will get multiple warnings of non convergence / fitted probabilities of 0/1\nglm(case ~ npa * age1,\n    family = binomial,\n    data = mwanza)|&gt; \n  tbl_regression(exponentiate = T) |&gt; \n  add_global_p(keep=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nnpa\n\n\n\n\n0.025\n\n\n    2\n—\n—\n\n\n\n\n    1\n0.44\n0.10, 1.78\n0.2\n\n\n    3\n6.40\n1.19, 36.7\n0.030\n\n\n    4\n0.00\n\n\n&gt;0.9\n\n\nage1\n\n\n\n\n&lt;0.001\n\n\n    1\n—\n—\n\n\n\n\n    2\n3.98\n1.52, 12.6\n0.009\n\n\n    3\n3.20\n1.14, 10.5\n0.037\n\n\n    4\n2.23\n0.77, 7.44\n0.2\n\n\n    5\n1.60\n0.55, 5.32\n0.4\n\n\n    6\n0.70\n0.20, 2.60\n0.6\n\n\nnpa * age1\n\n\n\n\n0.2\n\n\n    1 * 2\n1.06\n0.20, 5.62\n&gt;0.9\n\n\n    3 * 2\n0.22\n0.03, 1.43\n0.11\n\n\n    4 * 2\n97,773\n0.00,\n\n&gt;0.9\n\n\n    1 * 3\n0.62\n0.08, 4.12\n0.6\n\n\n    3 * 3\n0.18\n0.03, 1.20\n0.076\n\n\n    4 * 3\n1,217,553\n0.00,\n\n&gt;0.9\n\n\n    1 * 4\n1.62\n0.24, 10.5\n0.6\n\n\n    3 * 4\n0.18\n0.02, 1.33\n0.095\n\n\n    4 * 4\n523,548\n0.00,\n\n&gt;0.9\n\n\n    1 * 5\n0.70\n0.07, 5.21\n0.7\n\n\n    3 * 5\n0.10\n0.01, 0.81\n0.035\n\n\n    4 * 5\n1,095,798\n0.00,\n\n&gt;0.9\n\n\n    1 * 6\n5.19\n0.77, 35.7\n0.088\n\n\n    3 * 6\n0.20\n0.01, 2.81\n0.3\n\n\n    4 * 6\n478,324\n0.00,\n\n&gt;0.9\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\n\nTabulate the number of cases in each grouping of npa vs age1 (see note below).\n\n\n\nShow the code\nmwanza |&gt; tbl_summary(include = c(age1), by = npa)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n2 N = 3691\n1 N = 2001\n3 N = 1231\n4 N = 431\n\n\n\n\nage1\n\n\n\n\n\n\n\n\n\n\n    1\n37 (10%)\n62 (31%)\n8 (6.5%)\n1 (2.3%)\n\n\n    2\n86 (23%)\n40 (20%)\n28 (23%)\n3 (7.0%)\n\n\n    3\n57 (15%)\n25 (13%)\n33 (27%)\n6 (14%)\n\n\n    4\n58 (16%)\n20 (10%)\n24 (20%)\n10 (23%)\n\n\n    5\n70 (19%)\n28 (14%)\n22 (18%)\n13 (30%)\n\n\n    6\n61 (17%)\n25 (13%)\n8 (6.5%)\n10 (23%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\n\nWhat is the problem and how can it be resolved?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThis problem arises because there are no cases in the highest sex partner group and the youngest age group. Sparse data (bias), other names is complete/quasi separation problem.",
    "crumbs": [
      "Home",
      "2: Review of Logistic Regression"
    ]
  },
  {
    "objectID": "ASME_02.html#b-1",
    "href": "ASME_02.html#b-1",
    "title": "2: Review of Logistic Regression",
    "section": "4b",
    "text": "4b\nIn order to test for interaction we need to combine npa group 4 with npa group 3. Generate a new variable (eg npa2) with this regrouping. Refit the interaction model using npa2 in place of npa. Is there evidence of any interaction?\n\n\nShow the code\n# Create a new variable, relevel and label\nmwanza &lt;- mwanza |&gt; \n  mutate(partners = case_when(npa == \"1\" ~ \"&lt;=1\",\n              npa == \"2\" ~ \"2-4\",\n              npa == \"3\" | npa == \"4\" ~ \"&gt;=5\"),\n    partners = fct_relevel(partners,\"2-4\")\n  )\n\n# Check it worked well\nmwanza |&gt; tbl_summary(include = c(age1), by = partners)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n2-4 N = 3691\n&lt;=1 N = 2001\n&gt;=5 N = 1661\n\n\n\n\nage1\n\n\n\n\n\n\n\n\n    1\n37 (10%)\n62 (31%)\n9 (5.4%)\n\n\n    2\n86 (23%)\n40 (20%)\n31 (19%)\n\n\n    3\n57 (15%)\n25 (13%)\n39 (23%)\n\n\n    4\n58 (16%)\n20 (10%)\n34 (20%)\n\n\n    5\n70 (19%)\n28 (14%)\n35 (21%)\n\n\n    6\n61 (17%)\n25 (13%)\n18 (11%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\nShow the code\nglm(case ~ partners * age1,\n    family = binomial,\n    data = mwanza)|&gt; \n  tbl_regression(exponentiate = T) |&gt; \n  add_global_p(keep=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\npartners\n\n\n\n\n0.018\n\n\n    2-4\n—\n—\n\n\n\n\n    &lt;=1\n0.44\n0.10, 1.78\n0.2\n\n\n    &gt;=5\n5.12\n0.99, 27.1\n0.048\n\n\nage1\n\n\n\n\n&lt;0.001\n\n\n    1\n—\n—\n\n\n\n\n    2\n3.98\n1.52, 12.6\n0.009\n\n\n    3\n3.20\n1.14, 10.5\n0.037\n\n\n    4\n2.23\n0.77, 7.44\n0.2\n\n\n    5\n1.60\n0.55, 5.32\n0.4\n\n\n    6\n0.70\n0.20, 2.60\n0.6\n\n\npartners * age1\n\n\n\n\n0.5\n\n\n    &lt;=1 * 2\n1.06\n0.20, 5.62\n&gt;0.9\n\n\n    &gt;=5 * 2\n0.26\n0.04, 1.62\n0.14\n\n\n    &lt;=1 * 3\n0.62\n0.08, 4.12\n0.6\n\n\n    &gt;=5 * 3\n0.30\n0.05, 1.90\n0.2\n\n\n    &lt;=1 * 4\n1.62\n0.24, 10.5\n0.6\n\n\n    &gt;=5 * 4\n0.35\n0.05, 2.25\n0.3\n\n\n    &lt;=1 * 5\n0.70\n0.07, 5.21\n0.7\n\n\n    &gt;=5 * 5\n0.41\n0.06, 2.65\n0.3\n\n\n    &lt;=1 * 6\n5.19\n0.77, 35.7\n0.088\n\n\n    &gt;=5 * 6\n0.51\n0.06, 4.33\n0.5\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\nShow the code\n# Model with interaction\nlogit_inter &lt;- glm(case ~ partners * age1,\n    family = binomial,\n    data = mwanza)\n\n# Model without interaction\nlogit_without &lt;- glm(case ~ partners + age1,\n    family = binomial,\n    data = mwanza)\n\n# Likelihood ratio test\nlmtest::lrtest(logit_without, logit_inter)\n\n\n\n\n\n\n#Df\nLogLik\nDf\nChisq\nPr(&gt;Chisq)\n\n\n\n\n8\n-385\nNA\nNA\nNA\n\n\n18\n-380\n10\n9.4\n0.49\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nUsing partners variable in the analysis and conducting the interaction and no interaction model, the data are compatible with null hypothesis of no interaction: LRT gives \\(\\chi_{10}^2\\)=9.43, p=0.49.",
    "crumbs": [
      "Home",
      "2: Review of Logistic Regression"
    ]
  },
  {
    "objectID": "ASME_15.html",
    "href": "ASME_15.html",
    "title": "15: Analysis of quantitative data",
    "section": "",
    "text": "This computer practical uses the whitehal.dta data set, a subset of data from the Whitehall cohort study. It contains data on risk factors for ischaemic heart disease collected in male civil servants between 1967-69. The variables we are interested in were all collected at entry to the study and so the data can be thought of as cross-sectional. Systolic blood pressure (sbp) is the quantitative outcome, and the aim of the practical is to quantify the relationship between sbp and occupational grade (grade4).\nThese are the variables of interest: * Outcome: systolic blood pressure (continuous: sbp) * Exposure: job grade (categorical: grade4) * Confounder: age (continuous: agein)\nNote that in the data grade4 is coded 1=admin; 2=professional/executive; 3=clerical; 4=other\n\n\nShow the code\nlibrary(haven) \n# create table\nlibrary(gtsummary)\n# data wrangling and other functions\nlibrary(tidyverse)\n# if you want to have a output similar to stata\nlibrary(tidylog)\n#cox\nlibrary(survival)\n\n# Limit significant digits to 3, remove scientific notation (most of the time, scipen=999 removes all time)\noptions(digits = 3, scipen = 9)\n\n\n\nQ1\nFind the mean (systolic) blood pressure by categories of grade4\n\n\nShow the code\nwhite &lt;- read_dta(\"datasets/WHITEHAL.DTA\") |&gt; \n  mutate(across(where(is.labelled),as_factor))\n\n\n\n\nShow the code\nwhite |&gt; \n  mutate(grade4 = as.factor(grade4)) |&gt; \n  group_by(grade4) |&gt; \n  summarise(mean_sbp = mean(sbp),\n            sd_sbp = sd(sbp),\n            median_sbp = median(sbp),\n            iqr_sbp = IQR(sbp))\n\n\n\n\n\n\ngrade4\nmean_sbp\nsd_sbp\nmedian_sbp\niqr_sbp\n\n\n\n\n1\n133\n19.1\n132\n22.0\n\n\n2\n135\n19.5\n133\n27.0\n\n\n3\n139\n23.9\n136\n31.0\n\n\n4\n139\n24.8\n137\n34.5\n\n\n\n\n\n\n\n\nQ2\nEstimate the regression model for sbp with grade categories as explanatory variables. What is the expected sbp with 95% confidence intervals:\n\nfor a man in grade 1?\n\nfor a man in grade 4?\n\nCompare these estimates to your results for question 1.\n\n\nShow the code\nwhite &lt;- white |&gt; \n  mutate(grade4 = as.factor(grade4))\n\nlm_model &lt;- lm(sbp ~ grade4, data=white)\n\nmarginaleffects::avg_predictions(lm_model, variables = \"grade4\") |&gt; as_tibble()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngrade4\nestimate\nstd.error\nstatistic\np.value\ns.value\nconf.low\nconf.high\n\n\n\n\n1\n133\n2.271\n58.7\n0\nInf\n129\n138\n\n\n2\n135\n0.629\n214.2\n0\nInf\n133\n136\n\n\n3\n139\n1.193\n116.7\n0\nInf\n137\n142\n\n\n4\n139\n1.583\n87.5\n0\nInf\n135\n142\n\n\n\n\n\n\nShow the code\n# you can also get direct results fitting a model without intercept\n#lm_no_intercept &lt;- lm(sbp ~ -1 + grade4, data=white)\n#broom::tidy(lm_no_intercept, conf.int=T)\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nThe code marginaleffects::avg_predictions generates the prediction of the model by each level of the variable defined in “variables”. Also, if you fit a model without intercept, it will provide the same answers (in this case without other variables)\n\n\n\n\n\nQ3\nUsing the output of the model you fitted in question 2, do you have evidence to suggest that systolic blood pressure is associated with occupational grade?\n\n\nShow the code\nempty_model &lt;-lm(sbp ~ 1, data = white)\nanova(empty_model, lm_model)\n\n\n\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n\n1676\n740195\nNA\nNA\nNA\nNA\n\n\n1673\n733272\n3\n6923\n5.26\n0.001\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe anova (F test) indicates that compared to the null model, the new model with 3 more parameters (Df=3) has significantly improved the fit (F=5.27 and p=0.0013)\n\n\n\n\n\nQ4\nStudy the association between age at entry (agein) and sbp. Some of the tools you may wish to use are scatter plots, summaries of sbp by categories of agein, and regression models treating agein as linear, quadratic or categorical.\n\n\nShow the code\nwhite |&gt; \n  ggplot(aes(agein, sbp))+\n  geom_point()+\n  geom_smooth() # add a LOESS - Locally estimated scatterplot smoothing - curve\n\n\n\n\n\n\n\n\n\nShow the code\n# recode age\n\nwhite &lt;- white |&gt; \n  mutate(\n    agegroup = case_when(\n      agein&gt;40 & agein&lt;=45 ~ \"41-45\",\n      agein&lt;=50 ~ \"46-50\",\n      agein &lt;= 55 ~ \"51-55\",\n      agein &lt;= 60 ~ \"56-60\",\n      agein &lt;= 70 ~ \"61-70\"\n    )\n  )\n\nwhite |&gt; \n  group_by(agegroup) |&gt; \n    summarise(mean_sbp = mean(sbp),\n            sd_sbp = sd(sbp),\n            median_sbp = median(sbp),\n            iqr_sbp = IQR(sbp))\n\n\n\n\n\n\nagegroup\nmean_sbp\nsd_sbp\nmedian_sbp\niqr_sbp\n\n\n\n\n41-45\n130\n17.2\n129\n22.0\n\n\n46-50\n132\n19.4\n130\n26.0\n\n\n51-55\n135\n19.0\n132\n25.8\n\n\n56-60\n139\n22.2\n137\n29.0\n\n\n61-70\n146\n24.3\n144\n31.2\n\n\n\n\n\n\nShow the code\n# Models\n#Linear\nlm_lin &lt;- lm(sbp ~ agein, data = white)\n#marginaleffects::plot_predictions(lm_lin, condition = \"agein\")\n# Quadratic\nlm_qd &lt;- lm(sbp ~ agein + I(agein*agein), data = white)\n\nmarginaleffects::plot_predictions(lm_qd, condition = \"agein\")+\n  geom_point(data = white,aes(agein,sbp), alpha=0.1, color=\"blue\")+\n  labs(title=\"Prediction - Age squared\")\n\n\n\n\n\n\n\n\n\nShow the code\n# compare models\nanova(lm_lin, lm_qd)\n\n\n\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n\n1675\n697619\nNA\nNA\nNA\nNA\n\n\n1674\n694908\n1\n2711\n6.53\n0.011\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe F-test indicate that including the quadratic term improves the fit.\n\n\n\n\n\nQ5\nBefore looking at the data, do you think that age may confound the relationship between grade4 and sbp? Now fit a linear regression model to find out if age is a confounder or not. Is there evidence to suggest that occupational grade is independently associated with systolic blood pressure (i.e. after adjustment for age)? Write a brief conclusion of your findings about the association between occupational grade and systolic blood pressure.\n\n\nShow the code\nlm_model_f &lt;- lm(sbp ~ grade4 + agein +I(agein*agein), data=white)\nbroom::tidy(lm_model_f, conf.int=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n167.975\n28.80\n5.832\n0.000\n111.485\n224.466\n\n\ngrade42\n0.374\n2.30\n0.163\n0.871\n-4.135\n4.883\n\n\ngrade43\n1.482\n2.54\n0.583\n0.560\n-3.502\n6.466\n\n\ngrade44\n-0.211\n2.76\n-0.076\n0.939\n-5.617\n5.195\n\n\nagein\n-2.000\n1.10\n-1.813\n0.070\n-4.164\n0.164\n\n\nI(agein * agein)\n0.026\n0.01\n2.479\n0.013\n0.005\n0.046\n\n\n\n\n\n\n\n\nShow the code\nanova(lm_model_f,\n      lm(sbp ~ agein + I(agein*agein), white))\n\n\n\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n\n1671\n694491\nNA\nNA\nNA\nNA\n\n\n1674\n694908\n-3\n-417\n0.335\n0.8\n\n\n\n\n\n\n\n\nShow the code\nwhite |&gt; \n  ggplot(aes(grade4,agein, color=grade4))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nOur conclusion is that systolic blood pressure appears to be associated with occupational grade but that this is only as a result of lower grade workers (coded 3, 4) being, on average, older. The real association is between age and systolic blood pressure.\n\n\n\n\n\nQ6\nObtain standardised residuals of your model and use these to check that the model assumptions are reasonable.\n\n\nShow the code\nwhite &lt;- white |&gt; \n  mutate(std_res = rstandard(lm_model_f))\n\nwhite |&gt; \n  ggplot(aes(std_res))+\n  geom_histogram(color=\"white\")\n\n\n\n\n\n\n\n\n\nShow the code\nwhite |&gt; \n  ggplot()+\n geom_qq(aes(sample=std_res)) +\n  geom_abline(color = \"red\") +\n  coord_fixed()\n\n\n\n\n\n\n\n\n\nShow the code\n# you can get a overall of diagnostics plots using performance::check_model\n#performance::check_model(lm_model_f) # try yourself\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA histogram of the residuals and the Normal quantile plot both show some positive skew, but not too bad considering the size of the sample. It isn’t necessary to plot both a histogram and a Normal quantile plot but both are shown here for demonstration.\nThe residuals versus fitted plot shows no obvious relationship between the residuals and the fitted values, and the variance seems to be constant over the fitted values (perhaps some increasing variability but difficult to say). A log-transformation of the outcome variable can remove the skew in the distribution of the residuals - see question 7.\n\n\n\n\n\nQ7\nYou probably found that the model residuals that you obtained in question 6 looked a bit skewed. A log-transformation of the outcome variable often removes skew.\n\nGenerate a new variable of log-transformed sbp\nEstimate the regression model for lsbp with grade categories as explanatory variables, equivalent to the model you fitted in question 2.\n\n\n\nShow the code\nwhite &lt;- white |&gt; \n  mutate(log_sbp = log(sbp))\nlm_model_log &lt;- lm(log_sbp ~ grade4, data=white)\nbroom::tidy(lm_model_log, conf.int=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n4.882\n0.016\n299.814\n0.000\n4.850\n4.914\n\n\ngrade42\n0.010\n0.017\n0.601\n0.548\n-0.023\n0.043\n\n\ngrade43\n0.040\n0.018\n2.156\n0.031\n0.004\n0.076\n\n\ngrade44\n0.034\n0.020\n1.703\n0.089\n-0.005\n0.073\n\n\n\n\n\n\n\nObtain standardised residuals of this model and use these to check that the model assumptions are reasonable. Are the assumptions more appropriate now that you have log-transformed sbp?\n\n\n\nShow the code\nwhite &lt;- white |&gt; \n  mutate(std_res_log = rstandard(lm_model_log))\n\nwhite |&gt; \n  ggplot(aes(std_res_log))+\n  geom_histogram(color=\"white\")\n\n\n\n\n\n\n\n\n\nShow the code\nwhite |&gt; \n  ggplot()+\n geom_qq(aes(sample=std_res_log)) +\n  geom_abline(color = \"red\") +\n  coord_fixed()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe residuals are more symmetrical now that sbp has been log-transformed. The plot of the residuals versus fitted shows no obvious pattern, and the variance of the residuals does not seem to be very different across grades. The model assumptions are now more appropriate. Note that there are now only 4 different fitted values, because the only explanatory variables in the model are categories of grade. In question 6 the fitted values depended on grade and age and were therefore continuous.\n\n\n\n\nThe parameter estimates from a linear regression model with a log-transformed outcome can be back-transformed by taking the exponential of the estimate. Compute the back-transformed estimate for occupational grade 4 compared to occupational grade 1\n\n\n\nShow the code\nbroom::tidy(lm_model_log, conf.int=T, exponentiate=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n131.94\n0.016\n299.814\n0.000\n127.791\n136.22\n\n\ngrade42\n1.01\n0.017\n0.601\n0.548\n0.977\n1.04\n\n\ngrade43\n1.04\n0.018\n2.156\n0.031\n1.004\n1.08\n\n\ngrade44\n1.03\n0.020\n1.703\n0.089\n0.995\n1.07\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe back-transformed estimate for grade 4 compared to grade 1 is 1.034. This means that sbp is expected to be 3.4% higher (or 1.034 times higher) in workers in grade 4 compared to workers in grade 1\n\\[\nlog(sbp) = a + \\beta_2*grade_2+\\beta_3*grade_3+\\beta_4*grade_4\n\\newline\n\\text{for }grade_{4}\\text{ the other betas will be 0, so}\nlog(sbp) = a + \\beta_4*grade_4\n\\newline\nlog(sbp) - a = \\beta_4*grade_4\n\\newline\na = log(sbp|grade_1)\n\\newline\nlog(sbp) - log(sbp|grade_1) = \\beta_4*grade_4\n\\newline\ngrade_4=1\n\\newline\nlog(sbp) - log(sbp|grade_1) = \\beta_4\n\\newline\nlog((sbp|grade_4)/(sbp|grade_1)) = \\beta_4\n\\newline\n(sbp|grade_4)/(sbp|grade_1) = exp(\\beta_4)\n\\]",
    "crumbs": [
      "15: Analysis of quantitative data"
    ]
  },
  {
    "objectID": "review.html",
    "href": "review.html",
    "title": "Additional Topics",
    "section": "",
    "text": "This document cover some additional data wrangling steps need to do something in R, when compared to STATA\nlibrary(haven) \n# create table\nlibrary(gtsummary)\n# data wrangling and other functions\nlibrary(tidyverse)\n# if you want to have a output similar to stata\nlibrary(tidylog)\n#cox\nlibrary(survival)\n# plots survival\nlibrary(ggsurvfit)\n# Epi - additional splitting\nlibrary(Epi)\n# Limit significant digits to 2, remove scientific notation\noptions(digits = 3, scipen = 9)\npapua_raw &lt;- read_dta(\"datasets/pngnew.dta\") |&gt; \n  mutate(across(where(is.labelled),as_factor))"
  },
  {
    "objectID": "review.html#epi",
    "href": "review.html#epi",
    "title": "Additional Topics",
    "section": "Epi",
    "text": "Epi\nLet’s see how to do it using Epi (easy way)\n\n# Lets define a object with all time variables as numeric\npapua_epi &lt;- papua_raw |&gt; \n  mutate(\n    timein_calyear = cal.yr(timein, format=\"%Y-%m-%d\"),\n    timeout_calyear = cal.yr(timeout, format =\"%Y-%m-%d\"),\n    dob_calyear = cal.yr(dob, format = \"%Y-%m-%d\")\n  )\n# Define as Lexis object with timescales calendar time and age\nlexis_exp &lt;- Lexis(entry = list( period=timein_calyear ),\n               exit = list( period=timeout_calyear, age=timeout_calyear-dob_calyear),\n               exit.status = any,\n               data = papua_epi)\n\nNOTE: entry.status has been set to 0 for all.\n\n# example of splitting\n# now you can split by different cutoffs in each timescale\n# Split time along two time-axes\nlexis_split_per &lt;- splitLexis( lexis_exp, breaks = c(1983), time.scale=\"period\")\nlexis_split_per_age&lt;- splitLexis( lexis_split_per, breaks = c(3,6), time.scale=\"age\" )\nlexis_split_per_age |&gt; as_tibble() |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlex.id\nperiod\nage\nlex.dur\nlex.Cst\nlex.Xst\nid\nsex\nvacc\nany\nanyprev\ntimein\ntimeout\ndob\ndatevac\ntimein_calyear\ntimeout_calyear\ndob_calyear\n\n\n\n\n1\n1982\n5.84\n0.157\n0\n0\n1077\n1\n2\n0\n0\n1982-02-17\n1983-06-13\n1976-04-15\n1982-02-17\n1982\n1983\n1976\n\n\n1\n1982\n6.00\n0.714\n0\n0\n1077\n1\n2\n0\n0\n1982-02-17\n1983-06-13\n1976-04-15\n1982-02-17\n1982\n1983\n1976\n\n\n1\n1983\n6.71\n0.446\n0\n0\n1077\n1\n2\n0\n0\n1982-02-17\n1983-06-13\n1976-04-15\n1982-02-17\n1982\n1983\n1976\n\n\n2\n1982\n5.13\n0.867\n0\n0\n2228\n2\n2\n0\n0\n1981-10-27\n1983-01-14\n1976-09-08\n1981-10-27\n1982\n1983\n1977\n\n\n2\n1983\n6.00\n0.314\n0\n0\n2228\n2\n2\n0\n0\n1981-10-27\n1983-01-14\n1976-09-08\n1981-10-27\n1982\n1983\n1977\n\n\n2\n1983\n6.31\n0.035\n0\n0\n2228\n2\n2\n0\n0\n1981-10-27\n1983-01-14\n1976-09-08\n1981-10-27\n1982\n1983\n1977\n\n\n\n\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nThis new dataset has the columns period, age, lex.dur, lex.cst and lex.xst - these are the variables that are updated through the process.\nperiod is the calendar period\nage is the age\nlex.dur is the pyears in that period\nlex.Cst is the status (enter) of the individual in that period\nlex.Xst is the status (exit) of the individual in that period"
  },
  {
    "objectID": "review.html#survival",
    "href": "review.html#survival",
    "title": "Additional Topics",
    "section": "survival",
    "text": "survival\nLet’s see how to do it using survival\n\n# Lets define a object with only one entry per person\nz_int &lt;- papua_raw |&gt; \n  group_by(id) |&gt; \n  summarise(entry = (min(timein)),\n            exit = (max(timeout)),\n            dob = unique(dob),\n            timestudy = exit-entry)\nz &lt;- tmerge(z_int,z_int,id=id, tstart=entry,\n            tstop=exit)\n\nz &lt;- tmerge(z,\n            papua_raw,\n            id = id,\n            event_end = event(timeout, any))\n# now you need to break by calendar\nbreaks_cal &lt;- c(as.Date(\"1983-01-01\"))\n\nfor (i in 1:length(breaks_cal) ){\n  t &lt;- breaks_cal[i]\n  z_df &lt;- z_int  |&gt;  mutate(period_end_date = t)\n  z &lt;- tmerge(z,z_df, id=id, per1=tdc(period_end_date))\n  names(z)[names(z)==\"per1\"] &lt;- paste0(\"p_\",i)\n}\n\n\n# now you need to break by calendar\nbreaks_age &lt;- c(3*365.25,6*365.25)\n\nfor (i in 1:length(breaks_age) ){\n  t &lt;- breaks_age[i]\n  z_df &lt;- z_int  |&gt;  mutate(age_end_date = dob + t)\n  z &lt;- tmerge(z,z_df, id=id, per1=tdc(age_end_date))\n  names(z)[names(z)==\"per1\"] &lt;- paste0(\"age_\",i)\n}\nz |&gt; dplyr::select(id,tstart, tstop,dob, event_end) |&gt;\n  mutate(\n    age = as.numeric(tstart - dob)/365.25,\n    pyrs = as.numeric(tstop - tstart)/365.25) |&gt; \n  as_tibble() |&gt; head()\n\n\n\n\n\nid\ntstart\ntstop\ndob\nevent_end\nage\npyrs\n\n\n\n\n1077\n1982-02-17\n1982-04-15\n1976-04-15\n0\n5.84\n0.157\n\n\n1077\n1982-04-15\n1983-01-01\n1976-04-15\n0\n6.00\n0.713\n\n\n1077\n1983-01-01\n1983-06-13\n1976-04-15\n0\n6.71\n0.446\n\n\n2228\n1981-10-27\n1982-09-08\n1976-09-08\n0\n5.13\n0.867\n\n\n2228\n1982-09-08\n1983-01-01\n1976-09-08\n0\n6.00\n0.313\n\n\n2228\n1983-01-01\n1983-01-14\n1976-09-08\n0\n6.31\n0.036\n\n\n\n\n\n\nYou can see it match the output from Epi."
  },
  {
    "objectID": "review.html#using-cluster-se",
    "href": "review.html#using-cluster-se",
    "title": "Additional Topics",
    "section": "Using cluster SE",
    "text": "Using cluster SE\nLet’s see how to calculate an overall incidence rate when the data is clustered.\n\npapua_inc &lt;- papua_raw |&gt; \n  mutate(pyears = as.numeric((timeout-timein))/365.25) #using in years to match the common pattern in the stset scale=365.25\n\nWe can calculate this using a Poisson Model (valid point estimate) and using a cluster standard error (it’s different than “robust standard error” alone)\n\nmodel_inc &lt;- glm(any ~ 1+offset(log(pyears)),\n             family = poisson,\n             data = papua_inc)\nparameters::model_parameters(model_inc,  \n                             vcov = \"vcovCL\",\n                             vcov_args = list(cluster = papua_inc$id),\n                             exponentiate=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nz\ndf_error\np\n\n\n\n\n(Intercept)\n0.944\n0.029\n0.95\n0.889\n1\n-1.9\nInf\n0.057\n\n\n\n\n\n\nCheck the difference without cluster SE\n\nparameters::model_parameters(model_inc,\n                             exponentiate=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nz\ndf_error\np\n\n\n\n\n(Intercept)\n0.944\n0.02\n0.95\n0.906\n0.984\n-2.74\nInf\n0.006\n\n\n\n\n\n\nand now robust SE\n\nparameters::model_parameters(model_inc,  \n                             vcov = \"HC0\",\n                             exponentiate=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nz\ndf_error\np\n\n\n\n\n(Intercept)\n0.944\n0.023\n0.95\n0.9\n0.989\n-2.41\nInf\n0.016"
  },
  {
    "objectID": "review.html#using-gee",
    "href": "review.html#using-gee",
    "title": "Additional Topics",
    "section": "Using GEE",
    "text": "Using GEE\nUsing geepack package (or gee), because geepack\n\n# make sure the dataset is ordered by id\npapua_inc &lt;- papua_inc |&gt; \n  arrange(id)\n   gee_inc &lt;- geepack::geeglm(any ~ 1+offset(log(pyears)),\n                       id = id,\n             family = poisson,\n             data = papua_inc)\n  parameters::model_parameters(gee_inc, exponentiate=T) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nChi2\ndf_error\np\n\n\n\n\n(Intercept)\n0.944\n0.029\n0.95\n0.889\n1\n3.62\n1\n0.057"
  },
  {
    "objectID": "review.html#warning---random-effects-model-and-intercept",
    "href": "review.html#warning---random-effects-model-and-intercept",
    "title": "Additional Topics",
    "section": "Warning - Random Effects model and Intercept",
    "text": "Warning - Random Effects model and Intercept\nRemember from the class about Analysis of correlated outcome that a RE model is a “conditional” model. So the simple model with a intercept + random intercept will have a “conditional” interpretation, i.e., the fixed effect intercept depends on the RE intercept.\n\nlibrary(lme4)\nre_inc &lt;- glmer(any ~ 1+offset(log(pyears)) + (1|id),\n                    data = papua_inc,\n                    family = \"poisson\")\nparameters::model_parameters(re_inc, exponentiate=T) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nz\ndf_error\np\nEffects\nGroup\n\n\n\n\n(Intercept)\n0.720\n0.027\n0.95\n0.669\n0.774\n-8.89\nInf\n0\nfixed\n\n\n\nSD (Intercept)\n0.822\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\n\n\n\n\n\n# 1a. Fixed‐intercept estimate (conditional on random effect = 0)\nbeta0 &lt;- fixef(re_inc)[1]\n\n# 1b. Random‐intercept variance\nsigma2 &lt;- as.data.frame(VarCorr(re_inc))$vcov[1]\n\n# 2. Incidence‐rate estimates\n# • Cluster‐specific (conditional) IR  = exp(beta0)\nIR_cond   &lt;- exp(beta0)\n# • Marginal (population‐average) IR ≈ exp(beta0 + σ2/2)\nIR_marg   &lt;- exp(beta0 + sigma2/2)\n\nIf we accounted for the values from the Random effects intercept, we can get a incidence rate of 1.009"
  },
  {
    "objectID": "ASME_16.html",
    "href": "ASME_16.html",
    "title": "16: Additive & multiplicative models",
    "section": "",
    "text": "Q1\nPaperwork question\nSome notes: Additive scale in this practical can be seem as “risk difference”, while multiplicative as “risk ratio”. Don’t get confused with additive from “generalized additive models”\n\n\nQ2\nThis question uses data from a retrospective cohort study conducted in southern Africa investigating the risk factors for tuberculosis (TB) among male gold miners (contained in goldmine.dta). We want to examine the joint effect of HIV status (hiv coded 0 for negative and 1 for positive) and silicosis (silic coded 0 for none, 1 for possible, 2 for early, and 3 for advanced) on the incidence of TB (tb coded 0 for negative and 1 for positive). Follow-up is assessed using entry and exit.\n\n\nShow the code\nlibrary(haven) \n# create table\nlibrary(gtsummary)\n# data wrangling and other functions\nlibrary(tidyverse)\n# if you want to have a output similar to stata\nlibrary(tidylog)\n\n# Limit significant digits to 3, remove scientific notation (most of the time, scipen=999 removes all time)\noptions(digits = 4, scipen = 9)\n\n\n\n\nShow the code\ngold &lt;- read_dta(\"datasets/GOLDMINE.DTA\")|&gt; \n  mutate(across(where(is.labelled),as_factor))\n\n\n**Outcome*: - tb (tubercolosis diagnosis, 0/1)\n**Exposures*: - hiv (HIV status at entry: 0/1) - silic (silicosis grad: 0 = “none”, 1 = “possible”, 2 = “early”, 3 = “advanced”)\n**Time*: -entry (date of entry, formatted as number of days) -exit (date of exit, formatted as number of days) -dob (date of birth, formatted as number of days)\nCreate follow-up time (years) and drop missing data in silicosis\n\n\nShow the code\ngold &lt;- gold |&gt; \n  mutate(silic = as.factor(silic)) |&gt; \n  mutate(fup_y = (exit-entry)/365.25)\n\ngold_2 &lt;- gold |&gt; \n  drop_na(silic)\n\n\n\nUse the strate and streg (or glm) commands to examine the crude effect of HIV status on TB.\n\n\n\nShow the code\nmod1 &lt;- glm(tb ~ hiv + offset(log(fup_y)) , data=gold_2, family=poisson)\ntbl1 &lt;- tbl_regression(mod1, exponentiate=T)\nmod2 &lt;- glm(tb ~ silic+ offset(log(fup_y)) , data=gold_2, family=poisson)\ntbl2 &lt;- tbl_regression(mod2, exponentiate=T)\ntbl_merge(list(tbl1,tbl2),\n          tab_spanner = c(\"**HIV**\",\"**Silicosis**\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nHIV\n\n\nSilicosis\n\n\n\nIRR\n95% CI\np-value\nIRR\n95% CI\np-value\n\n\n\n\nHIV status at entry\n4.59\n3.48, 6.10\n&lt;0.001\n\n\n\n\n\n\n\n\nsilic\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    0\n\n\n\n\n\n\n—\n—\n\n\n\n\n    1\n\n\n\n\n\n\n1.83\n1.29, 2.54\n&lt;0.001\n\n\n    2\n\n\n\n\n\n\n3.53\n2.13, 5.53\n&lt;0.001\n\n\n    3\n\n\n\n\n\n\n3.58\n2.31, 5.35\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\n\nAre there any biological reasons why you might expect the effects of HIV status and silicosis on TB incidence to combine multiplicatively or additively?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nOne might expect the effects of HIV and silicosis on TB to combine additively because they have two separate pathways leading to active tuberculosis: HIV tends to cause TB through immunosuppression, whereas silicosis causes TB through lung impairment caused by prolonged silica dust exposure.\n\n\n\n\nExamine the joint effects of HIV status and silicosis on TB in a multiplicative Poisson model. Is there evidence of an interaction on the multiplicative scale?\n\n\n\nShow the code\n# gold_2_agg &lt;- gold_2 |&gt; \n#   group_by(hiv,silic) |&gt; \n#   summarise(n_tb = sum(tb),\n#       pyears = sum(fup_y))\n# \n# mod3 &lt;- glm(n_tb ~hiv+ silic +offset(log(pyears)), data=gold_2_agg, family=poisson)\n# mod31 &lt;- glm(n_tb ~hiv* silic +offset(log(pyears)), data=gold_2_agg, family=poisson)\n\nmod3 &lt;- glm(tb ~hiv+ silic+ offset(log(fup_y)) , data=gold_2, family=poisson)\nmod31 &lt;- glm(tb ~hiv*silic+ offset(log(fup_y)) , data=gold_2, family=poisson)\n\ntbl1 &lt;- tbl_regression(mod3, exponentiate=T)\ntbl2 &lt;- tbl_regression(mod31, exponentiate=T)\ntbl_merge(list(tbl1,tbl2),\n          tab_spanner = c(\"No interaction\",\"Interaction\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nNo interaction\n\n\nInteraction\n\n\n\nIRR\n95% CI\np-value\nIRR\n95% CI\np-value\n\n\n\n\nHIV status at entry\n4.82\n3.65, 6.41\n&lt;0.001\n4.85\n3.33, 7.16\n&lt;0.001\n\n\nsilic\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    0\n—\n—\n\n\n—\n—\n\n\n\n\n    1\n1.98\n1.40, 2.76\n&lt;0.001\n1.84\n1.02, 3.19\n0.035\n\n\n    2\n3.57\n2.16, 5.60\n&lt;0.001\n2.58\n0.89, 5.94\n0.046\n\n\n    3\n4.12\n2.65, 6.15\n&lt;0.001\n5.34\n2.86, 9.46\n&lt;0.001\n\n\nHIV status at entry * silic\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    HIV status at entry * 1\n\n\n\n\n\n\n1.12\n0.56, 2.31\n0.7\n\n\n    HIV status at entry * 2\n\n\n\n\n\n\n1.59\n0.57, 5.18\n0.4\n\n\n    HIV status at entry * 3\n\n\n\n\n\n\n0.60\n0.25, 1.40\n0.2\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nShow the code\nanova(mod3,mod31)\n\n\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n3943\n1423\nNA\nNA\nNA\n\n\n3940\n1420\n3\n2.786\n0.4259\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe LRT for interaction gives a p-value of 0.43, hence there is no evidence of an interaction on the multiplicative scale. The adjusted RRs for HIV status and silicosis are given in the model above; both effects are strong after adjusting for one another. We have no evidence to suggest that these effects do not combine multiplicatively, so there is an estimated 20-fold increase in the rate of developing TB among those HIV-positive who have advanced silicosis compared to those HIV-negative without silicosis (RR=4.82x4.12=19.86).\n\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nThe code in Stata first aggregate the dataset, it is not strictly necessary.\n\n\n\n\n\nShow the code\ncat(\"Expected/Observed number of TB cases\")\n\n\nExpected/Observed number of TB cases\n\n\nShow the code\ngold_2 |&gt;\n  mutate(\n    predicted_cases = predict(mod3, type = \"response\")\n  ) |&gt;\n  group_by(hiv, silic) |&gt;\n  summarise(\n    observed = sum(tb),\n    predicted = sum(predicted_cases)\n  )\n\n\n\n\n\n\nhiv\nsilic\nobserved\npredicted\n\n\n\n\n0\n0\n40\n40.127\n\n\n0\n1\n17\n18.329\n\n\n0\n2\n5\n6.956\n\n\n0\n3\n15\n11.589\n\n\n1\n0\n78\n77.873\n\n\n1\n1\n30\n28.671\n\n\n1\n2\n15\n13.044\n\n\n1\n3\n12\n15.411\n\n\n\n\n\n\nFor all covariates, the observed number of TB events is similar to the expected number under the multiplicative model.\n\nExamine the joint effects of HIV infection and silicosis on TB in an additive rate model. Is there evidence of an interaction on the additive scale?\n\nThe answer to part (iv) suggests that the multiplicative model is appropriate and we could stop here. There is no evidence of an interaction on the multiplicative scale and for two out of the three categories of silicosis, the interaction was positive rather than negative. Hence, there is no statistical evidence to suggest additive effects. Let’s try fitting the additive model anyway, on the grounds that it is biologically plausible.\n\n\nShow the code\n# Create rate variable\ngold_2 &lt;- gold_2 |&gt; \n  mutate(rate = tb/fup_y)\n\n# use the poisson distribution with identity link\nmod4 &lt;- glm(rate ~hiv+ silic , data=gold_2, family=poisson(link=\"identity\"),\n            weights = fup_y)\nmod41 &lt;- glm(rate ~hiv*silic , data=gold_2, family=poisson(link=\"identity\"),\n            weights = fup_y)\n\nanova(mod4,mod41)\n\n\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n3943\n1437\nNA\nNA\nNA\n\n\n3940\n1420\n3\n16.82\n0.0008\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe LRT is given by 16.82 [2*(-955.979- -964.390)] which is a chi-square with 3 df, giving p=0.0008 and so there is strong evidence of interaction on the additive scale. Note that all three interaction terms are positive and the “main effects” are also positive (so all RRs&gt;1), suggesting that the effects are more than additive (likely multiplicative).\n\n\n\n\n\nShow the code\n# tbl_regression(mod3, exponentiate=T)\n# tbl_regression(mod3, exponentiate=T)\n\ngold_2 |&gt; \n  mutate(\n    predicted_cases = predict(mod4,type = \"response\")\n  ) |&gt; group_by(hiv, silic) |&gt; \n  summarise(observed = sum(tb),\n            predicted= sum(predicted_cases*fup_y))\n\n\n\n\n\n\nhiv\nsilic\nobserved\npredicted\n\n\n\n\n0\n0\n40\n37.645\n\n\n0\n1\n17\n19.847\n\n\n0\n2\n5\n8.870\n\n\n0\n3\n15\n17.008\n\n\n1\n0\n78\n92.356\n\n\n1\n1\n30\n20.802\n\n\n1\n2\n15\n7.070\n\n\n1\n3\n12\n8.402\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFor some covariates, the observed number of TB events differs markedly from the expected number under the additive model. In summary, the strong evidence for an interaction (p=0.0008) and the discrepancies between the observed and expected values for the additive model suggest that the effects of HIV and silicosis do not combine additively.",
    "crumbs": [
      "16: Additive & multiplicative models"
    ]
  },
  {
    "objectID": "ASME_06.html",
    "href": "ASME_06.html",
    "title": "06: Stratifying on time for cohort studies",
    "section": "",
    "text": "Show the code\n# read \"dta\" files\nlibrary(haven) \n# create table\nlibrary(gtsummary)\n# data wrangling and other functions\nlibrary(tidyverse)\n# if you want to have a output similar to stata\nlibrary(tidylog)\n#cox\nlibrary(survival)\n# plots survival\nlibrary(ggsurvfit)\n# Limit significant digits to 2, remove scientific notation\noptions(digits = 2, scipen = 9)\n\n\n\nQ1\nOpen a log file, change to the directory where your ASME data have been copied and then read the Whitehall data, whitehal.dta. In this practical we are interested in the effect of job grade on CHD mortality.\n\n\nShow the code\nwhitehall &lt;- read_stata(\"datasets/WHITEHAL.DTA\")\n\n# data wrangling\nwhitehall &lt;- whitehall |&gt; \n  mutate(\n    id = as.integer(id),\n    all = as.integer(all), # NB outcomes must remain numerical\n    chd = as.integer(chd),\n    grade4 = case_when( # recoding as character using case_when, most models will recognize characters as factors with some exemptions (mgcv doesnt)\n      grade4 == 1 ~ \"admin\",\n      grade4 == 2 ~ \"profess\",\n      grade4 == 3 ~ \"clerical\",\n      grade4 == 4 ~ \"other\"\n    ),\n    smok = case_when(\n      smok == 1 ~ \"never\",\n      smok == 2 ~ \"ex\",\n      smok == 3 ~ \"1-14/day\",\n      smok == 4 ~ \"15-24/day\",\n      smok == 5 ~ \"25+/day\"\n    ),\n    grade = case_when(\n      grade == 1 ~ \"higher\",\n      grade == 2 ~ \"lower\"),\n    cholgrp = as.factor(cholgrp),\n    sbpgrp = as.factor(sbpgrp))\n\n\n\n\nQ2\nCompute the rates for the two grades of employment categories using the commands below. pyears()\nIn days\n\nShow the code\n# Calculate rates\npyears(Surv(time = as.numeric(timein), \n                                 time2 = as.numeric(timeout), \n                                 event = chd) ~ grade, data = whitehall, scale = 1) %&gt;%\n  summary(n = F, rate = T, ci.r = T, scale = 1000)\n\nCall: pyears(formula = Surv(time = as.numeric(timein), time2 = as.numeric(timeout), event = chd) ~ grade, data = whitehall, scale = 1)\nnumber of observations = 1677\n\n\n\ngrade\nEvents\nTime\nEvent rate\nCI (rate)\n\n\n\n\nhigher\n90\n7429107\n0.012\n0.0097 - 0.015\n\n\nlower\n64\n2653754\n0.024\n0.0186 - 0.031\n\n\n\nIn years\n\nShow the code\n# Calculate rates\npyears(Surv(time = as.numeric(timein), \n                                 time2 = as.numeric(timeout), \n                                 event = chd) ~ grade, data = whitehall) %&gt;%\n  summary(n = F, rate = T, ci.r = T, scale = 1000)\n\nCall: pyears(formula = Surv(time = as.numeric(timein), time2 = as.numeric(timeout), event = chd) ~ grade, data = whitehall)\nnumber of observations = 1677\n\n\n\ngrade\nEvents\nTime\nEvent rate\nCI (rate)\n\n\n\n\nhigher\n90\n20340\n4.4\n3.6 - 5.4\n\n\nlower\n64\n7266\n8.8\n6.8 - 11.2\n\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nCalculate rates stratified by exposure (the two grades of employment: grade).\nYou create a survival object with Surv(); it contains duration of follow-up and status at end of follow-up. You dont need to setup it globally as in STATA. You have freedom to use different timescales for each model\nYou then calculate stratified rates pyears(): in the formula, you use a Surv object, and then the stratification; you then pipe this into summary()\nThe argument “scale” from pyears() is to scaling the results, for example if your time is in days and want to report in years use scale = 365.25 (the default value)\n\n\n\nCalculate the RR by hand (from the two rates shown on the screen).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\(\\frac{8.8}{4.4}=2\\)\n\n\n\n\n\nQ3\nNow, set again the time and outcome variables with stset but this time, use the time of birth as the origin, i.e. organise the data according to current age.\n\nShow the code\n# Calculate rates\npyears(Surv(time = as.numeric(timein), \n                                 time2 = as.numeric(timeout), \n            origin = as.numeric(timebth),\n                                 event = chd) ~ grade, data = whitehall) %&gt;%\n  summary(n = F, rate = T, ci.r = T, scale = 1000)\n\nCall: pyears(formula = Surv(time = as.numeric(timein), time2 = as.numeric(timeout), origin = as.numeric(timebth), event = chd) ~ grade, data = whitehall)\nnumber of observations = 1677\n\n\n\ngrade\nEvents\nTime\nEvent rate\nCI (rate)\n\n\n\n\nhigher\n90\n20340\n4.4\n3.6 - 5.4\n\n\nlower\n64\n7266\n8.8\n6.8 - 11.2\n\n\n\n\n\nShow the code\n# I dont know any easy alternative to see the summary (similar to STATA)\nsummary(Surv(as.numeric(whitehall$timein)/365.25, \n     as.numeric(whitehall$timeout)/365.25,\n     origin = as.numeric(whitehall$timebth)/365.25,\n     whitehall$chd))\n\n\n     start         stop        status    \n Min.   :40   Min.   :44   Min.   :0.00  \n 1st Qu.:47   1st Qu.:64   1st Qu.:0.00  \n Median :52   Median :68   Median :0.00  \n Mean   :52   Mean   :69   Mean   :0.09  \n 3rd Qu.:57   3rd Qu.:73   3rd Qu.:0.00  \n Max.   :69   Max.   :86   Max.   :1.00  \n\n\n\n\nQ4, Q5 and Q6\nNext we need to split the individual follow-up times into intervals specific to different agebands.\nUse the stsplit command to create 5-years groups of current age between age 50 and 80 and 10-year groups for the youngest and oldest groups.\n\nShow the code\n# dividing by 365.25 to transform in years instead days\n# the variables used in time, time2,origin will be removed from the new dataset\nwhite_split &lt;- survSplit(\n  Surv(\n    time = as.numeric(timein) / 365.25,\n    time2 = as.numeric(timeout) / 365.25,\n    event = chd,\n    origin = as.numeric(timebth) / 365.25\n  ) ~ .,\n  data = whitehall,\n  cut = c(40, seq(50, 80, 5), 90),\n  episode = \"ageband\"\n)\n\nwhite_split |&gt;  filter(id == \"5001\") |&gt; \n  select(id,\n         tstart, tstop, ageband) |&gt; \n  left_join(whitehall |&gt; \n              select(id,timein,timeout,timebth) |&gt; \n              mutate(age_enter = (timein-timebth)/365.25)) |&gt; \n  gt::gt()\n\n\n\n\n\n\n\nid\ntstart\ntstop\nageband\nDate of entry (days)\nDate of exit (days)\nDate of birth (days)\nage_enter\n\n\n\n\n5001\n47\n50\n2\n1967-09-13\n1987-01-30\n1920-03-20\n47.4825448643908\n\n\n5001\n50\n55\n3\n1967-09-13\n1987-01-30\n1920-03-20\n47.4825448643908\n\n\n5001\n55\n60\n4\n1967-09-13\n1987-01-30\n1920-03-20\n47.4825448643908\n\n\n5001\n60\n65\n5\n1967-09-13\n1987-01-30\n1920-03-20\n47.4825448643908\n\n\n5001\n65\n67\n6\n1967-09-13\n1987-01-30\n1920-03-20\n47.4825448643908\n\n\n\n\n\n\n\nQ7\nNote that there is no change in the information about length of follow-up\n\nShow the code\n# Stratify by grade\n# use scale =1 because the time is already in years\npyears(Surv(tstart, tstop,chd) ~ grade,\n       data = white_split,\n       scale=1) %&gt;%\n  summary(n = F, rate = T, ci.r = T, scale = 1000)\n\nCall: pyears(formula = Surv(tstart, tstop, chd) ~ grade, data = white_split, scale = 1)\nnumber of observations = 6920\n\n\n\ngrade\nEvents\nTime\nEvent rate\nCI (rate)\n\n\n\n\nhigher\n90\n20340\n4.4\n3.6 - 5.4\n\n\nlower\n64\n7266\n8.8\n6.8 - 11.2\n\n\n\n\n\nQ8\nTabulate by agebands now\n\n\nShow the code\npyears(Surv(tstart, tstop,chd) ~ ageband,\n       data = white_split,\n       scale=1) |&gt; \n  summary(n = T, rate = T, ci.r = T, scale = 1000) #use n=T to see the number of individuals who were followed in each ageband\n\n\nCall: pyears(formula = Surv(tstart, tstop, chd) ~ ageband, data = white_split, \n    scale = 1)\n\nnumber of observations = 6920\n\n ageband    N     Events   Time   Event rate     CI (rate)    \n--------- ------ -------- ------ ------------ --------------- \n    2       722      1     3138      0.32      0.0081 -  1.8 \n    3      1078      9     4427      2.03      0.9296 -  3.9 \n    4      1400     17     6003      2.83      1.6496 -  4.5 \n    5      1500     38     6166      6.16      4.3614 -  8.5 \n    6      1149     41     4398      9.32      6.6898 - 12.6 \n    7       686     29     2442     11.87      7.9517 - 17.1 \n    8       311     15      912     16.45      9.2047 - 27.1 \n    9        74      4      118     33.78      9.2032 - 86.5 \n\n\n\n\nQ9\nCalculate the ageband-specific RRs for Low grade versus High grade using stmh and assess whether the effect of grade is the same across all the strata. Is it necessary to report the stratum specific estimates? Do you think that age confounds the relationship between job grade and CHD mortality?\n\n\nShow the code\npyears(Surv(tstart, tstop,chd) ~ ageband+grade,\n       data = white_split,\n       scale=1)|&gt; \n  summary(n = T, rate = T, ci.r = T, scale = 1000) \n\n\nCall: pyears(formula = Surv(tstart, tstop, chd) ~ ageband + grade, \n    data = white_split, scale = 1)\n\nnumber of observations = 6920\n\n---------- \n    N     \n  Events  \n   Time   \nEvent rate\nCI (rate) \n---------- \n\n--------------------------------------- \n             grade                      \nageband     higher           lower      \n------- --------------- --------------- \n              603             119       \n                0               1       \n   2        2667.9           470.4      \n               0.0             2.1      \n          0.000-  1.383   0.054- 11.843 \n \n              871             207       \n                6               3       \n   3        3650.2           776.8      \n               1.6             3.9      \n          0.603-  3.578   0.796- 11.287 \n \n             1074             326       \n               12               5       \n   4        4737.2          1266.0      \n               2.5             3.9      \n          1.309-  4.425   1.282-  9.216 \n \n             1080             420       \n               21              17       \n   5        4493.7          1672.0      \n               4.7            10.2      \n          2.893-  7.144   5.923- 16.279 \n \n              779             370       \n               21              20       \n   6        2900.6          1497.5      \n               7.2            13.4      \n          4.482- 11.067   8.158- 20.626 \n \n              425             261       \n               20               9       \n   7        1407.6          1034.9      \n              14.2             8.7      \n          8.679- 21.944   3.977- 16.509 \n \n              163             148       \n                9               6       \n   8         440.4           471.7      \n              20.4            12.7      \n          9.344- 38.793   4.668- 27.688 \n \n               31              43       \n                1               3       \n   9          42.2            76.2      \n              23.7            39.4      \n          0.600-132.056   8.116-115.009 \n--------------------------------------- \n\n\nShow the code\n# To get the RR of grade adjusted for ageband, we need additional steps\n\ndt_rates &lt;- pyears(Surv(tstart, tstop,chd) ~ ageband+grade,\n       data = white_split,\n       scale=1,\n       data.frame = T) \n# ageband is coded as numeric in the output\ndt_rates$data$ageband &lt;- as.factor(dt_rates$data$ageband)\ndt_mh &lt;- dt_rates$data |&gt; arrange(desc(grade))\n\n\nPainful to do MH in R\n\n\nShow the code\ndat.tab04 &lt;- sapply(2:length(unique(dt_mh$ageband)), function(x) \n   as.matrix(dt_mh[dt_mh$ageband == x,c(5,3)], ncol = 2, byrow = TRUE), \n   simplify = \"array\")\nepiR::epi.2by2(dat = dat.tab04, method = \"cohort.time\", digits = 2, \n   conf.level = 0.95, interpret = FALSE, \n   outcome = \"as.columns\")\n\n\n             Outcome +     Time at risk                 Inc rate *\nExposed +           61 7189.35230511529        0.85 (0.65 to 1.09)\nExposed -           89 20297.5953348253        0.44 (0.35 to 0.54)\nTotal              150 27486.9476399405        0.55 (0.46 to 0.64)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nInc rate ratio (crude)                         1.94 (1.37, 2.71)\nInc rate ratio (M-H)                           1.38 (1.01, 1.90)\nInc rate ratio (crude:M-H)                     1.40\nAttrib rate in the exposed (crude) *           0.41 (0.178, 0.642)\nAttrib rate in the exposed (M-H) *             0.22 (-0.016, 0.465)\nAttrib rate (crude:M-H)                        1.83\n-------------------------------------------------------------------\n Wald confidence limits\n M-H: Mantel-Haenszel; CI: confidence interval\n * Outcomes per 100 units of population time at risk \n\n\nModel based is way better\n\n\nShow the code\nmod1 &lt;-  glm(event ~ grade + ageband + offset(log(pyears)),\n      family = poisson,\n      data= dt_rates$data) \nmod_int &lt;-  glm(event ~ grade*ageband + offset(log(pyears)),\n      family = poisson,\n      data= dt_rates$data) \ntbl_regression(mod1,exponentiate = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\ngrade\n\n\n\n\n\n\n\n\n    higher\n—\n—\n\n\n\n\n    lower\n1.41\n1.01, 1.96\n0.040\n\n\nageband\n\n\n\n\n\n\n\n\n    2\n—\n—\n\n\n\n\n    3\n6.32\n1.19, 117\n0.080\n\n\n    4\n8.68\n1.78, 156\n0.036\n\n\n    5\n18.5\n4.01, 328\n0.004\n\n\n    6\n27.2\n5.92, 483\n0.001\n\n\n    7\n33.7\n7.18, 601\n&lt;0.001\n\n\n    8\n45.2\n9.10, 819\n&lt;0.001\n\n\n    9\n88.9\n13.1, 1,746\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nCheck interaction\n\n\nShow the code\nlmtest::lrtest(mod1,mod_int)\n\n\n\n\n\n\n#Df\nLogLik\nDf\nChisq\nPr(&gt;Chisq)\n\n\n\n\n9\n-35\nNA\nNA\nNA\n\n\n16\n-29\n7\n13\n0.06\n\n\n\n\n\n\nDifferent answers from STATA output. Here, we are modelling it using Poisson and testing interaction using a likelihood test. Instead, in the Stata solutions it is with stratified rate ratios (Mantel-Haenszel)\nAll subsequent questions will be answered using model based / likelihood ratio tests for interactions\n\n\nQ10\nUsing strate and stmh examine (a) the effect of smoking on CHD mortality, (b) whether smoking confounds the relationship between job grade and CHD mortality. You may wish to recode the smoking variable into three categories (i) never, (ii) ex, (iii) current smokers\n\n\nShow the code\n# Recode\nwhite_split &lt;- white_split |&gt; \n  mutate(smok3 = as.factor(case_when(smok == \"never\" ~ \"never\",\n                                     smok == \"ex\" ~ \"ex\",\n                                     smok == \"1-14/day\" ~ \"current\",\n                                     smok == \"15-24/day\" ~ \"current\",\n                                     smok == \"25+/day\" ~ \"current\")),\n         smok3 = fct_relevel(smok3, \"never\", \"ex\", \"current\"))# Order level\n\n\n\npyears(Surv(tstart, tstop,chd) ~ smok3+grade,\n       data = white_split,\n       scale=1)|&gt; \n  summary(n = T, rate = T, ci.r = T, scale = 1000) \n\n\nCall: pyears(formula = Surv(tstart, tstop, chd) ~ smok3 + grade, data = white_split, \n    scale = 1)\n\nnumber of observations = 6920\n\n---------- \n    N     \n  Events  \n   Time   \nEvent rate\nCI (rate) \n---------- \n\n------------------------------- \n           grade                \n smok3    higher       lower    \n------- ----------- ----------- \n           1094         245     \n              6           5     \n never    4603.9       988.2    \n             1.3         5.1    \n         0.48- 2.84  1.64-11.81 \n \n           2116         595     \n             38          17     \n  ex      8462.5      2308.1    \n             4.5         7.4    \n         3.18- 6.16  4.29-11.79 \n \n           1816        1054     \n             46          42     \ncurrent   7273.5      3969.3    \n             6.3        10.6    \n         4.63- 8.44  7.63-14.30 \n------------------------------- \n\n\nShow the code\n# To get the RR of grade adjusted for ageband, we need additional steps\n\ndt_rates &lt;- pyears(Surv(tstart, tstop,chd) ~ smok3+grade,\n       data = white_split,\n       scale=1,\n       data.frame = T) \ndt_mh &lt;- dt_rates$data \n\n\n\n\nShow the code\nmod1 &lt;-  glm(event ~ grade + smok3 + offset(log(pyears)),\n      family = poisson,\n      data= dt_rates$data) \nmod_int &lt;-  glm(event ~ grade*smok3 + offset(log(pyears)),\n      family = poisson,\n      data= dt_rates$data) \ntbl_regression(mod1,exponentiate = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\ngrade\n\n\n\n\n\n\n\n\n    higher\n—\n—\n\n\n\n\n    lower\n1.76\n1.27, 2.43\n&lt;0.001\n\n\nsmok3\n\n\n\n\n\n\n\n\n    never\n—\n—\n\n\n\n\n    ex\n2.53\n1.38, 5.10\n0.005\n\n\n    current\n3.56\n1.98, 7.08\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nCheck interaction\n\n\nShow the code\nlmtest::lrtest(mod1,mod_int)\n\n\n\n\n\n\n#Df\nLogLik\nDf\nChisq\nPr(&gt;Chisq)\n\n\n\n\n4\n-15\nNA\nNA\nNA\n\n\n6\n-14\n2\n1.7\n0.42\n\n\n\n\n\n\n\n\nQ11\nExamine the effect of job grade on CHD mortality adjusted for ageband and smoking simultaneously. What do you conclude about the effect of job grade on CHD mortality having adjusted for both of these factors together?\n\n\nShow the code\npyears(Surv(tstart, tstop,chd) ~ smok3+grade+ageband,\n       data = white_split,\n       scale=1)|&gt; \n  summary(n = T, rate = T, ci.r = T, scale = 1000) \n\n\nCall: pyears(formula = Surv(tstart, tstop, chd) ~ smok3 + grade + ageband, \n    data = white_split, scale = 1)\n\nnumber of observations = 6920\n\n---------- \n    N     \n  Events  \n   Time   \nEvent rate\nCI (rate) \n---------- \n\n: ageband=2 \n--------------------------------------- \n             grade                      \n smok3      higher           lower      \n------- --------------- --------------- \n              162              21       \n                0               0       \n never       848.37           85.47     \n               0.00            0.00     \n          0.000-  4.348   0.000- 43.161 \n \n              221              35       \n                0               0       \n  ex         907.18          140.02     \n               0.00            0.00     \n          0.000-  4.066   0.000- 26.346 \n \n              220              63       \n                0               1       \ncurrent      912.38          244.96     \n               0.00            4.08     \n          0.000-  4.043   0.103- 22.745 \n--------------------------------------- \n: ageband=3 \n--------------------------------------- \n             grade                      \n smok3      higher           lower      \n------- --------------- --------------- \n              215              29       \n                0               0       \n never       935.63          124.46     \n               0.00            0.00     \n          0.000-  3.943   0.000- 29.640 \n \n              341              62       \n                1               1       \n  ex        1412.29          227.72     \n               0.71            4.39     \n          0.018-  3.945   0.111- 24.467 \n \n              315             116       \n                5               2       \ncurrent     1302.28          424.60     \n               3.84            4.71     \n          1.247-  8.960   0.570- 17.015 \n--------------------------------------- \n: ageband=4 \n--------------------------------------- \n             grade                      \n smok3      higher           lower      \n------- --------------- --------------- \n              247              41       \n                1               1       \n never      1118.70          166.52     \n               0.89            6.01     \n          0.023-  4.980   0.152- 33.459 \n \n              442             102       \n                5               1       \n  ex        1909.13          398.85     \n               2.62            2.51     \n          0.850-  6.112   0.063- 13.969 \n \n              385             183       \n                6               3       \ncurrent     1709.37          700.66     \n               3.51            4.28     \n          1.288-  7.640   0.883- 12.513 \n--------------------------------------- \n: ageband=5 \n--------------------------------------- \n             grade                      \n smok3      higher           lower      \n------- --------------- --------------- \n              231              53       \n                4               0       \n never       900.08          218.29     \n               4.44            0.00     \n          1.211- 11.378   0.000- 16.899 \n \n              461             129       \n                6               3       \n  ex        1979.09          530.70     \n               3.03            5.65     \n          1.113-  6.599   1.166- 16.520 \n \n              388             238       \n               11              14       \ncurrent     1614.51          923.05     \n               6.81           15.17     \n          3.401- 12.191   8.292- 25.448 \n--------------------------------------- \n: ageband=6 \n--------------------------------------- \n             grade                      \n smok3      higher           lower      \n------- --------------- --------------- \n              140              46       \n                0               0       \n never       500.40          187.88     \n               0.00            0.00     \n          0.000-  7.372   0.000- 19.634 \n \n              355             118       \n               12               9       \n  ex        1347.42          486.21     \n               8.91           18.51     \n          4.602- 15.557   8.464- 35.139 \n \n              284             206       \n                9              11       \ncurrent     1052.77          823.42     \n               8.55           13.36     \n          3.909- 16.228   6.669- 23.903 \n--------------------------------------- \n: ageband=7 \n--------------------------------------- \n             grade                      \n smok3      higher           lower      \n------- --------------- --------------- \n               71              30       \n                1               2       \n never       231.88          126.92     \n               4.31           15.76     \n          0.109- 24.029   1.908- 56.924 \n \n              201              88       \n               10               2       \n  ex         671.00          342.64     \n              14.90            5.84     \n          7.147- 27.407   0.707- 21.086 \n \n              153             143       \n                9               5       \ncurrent      504.72          565.31     \n              17.83            8.84     \n          8.154- 33.850   2.872- 20.640 \n--------------------------------------- \n: ageband=8 \n--------------------------------------- \n             grade                      \n smok3      higher           lower      \n------- --------------- --------------- \n               24              19       \n                0               1       \n never        63.93           72.80     \n               0.00           13.74     \n          0.000- 57.706   0.348- 76.532 \n \n               81              47       \n                4               0       \n  ex         215.82          152.47     \n              18.53            0.00     \n          5.050- 47.455   0.000- 24.193 \n \n               58              82       \n                5               5       \ncurrent      160.67          246.39     \n              31.12           20.29     \n         10.104- 72.623   6.589- 47.357 \n--------------------------------------- \n: ageband=9 \n--------------------------------------- \n             grade                      \n smok3      higher           lower      \n------- --------------- --------------- \n                4               6       \n                0               1       \n never         4.87            5.87     \n               0.00          170.29     \n          0.000-756.995   4.311-948.797 \n \n               14              14       \n                0               1       \n  ex          20.55           29.48     \n               0.00           33.92     \n          0.000-179.535   0.859-188.976 \n \n               13              23       \n                1               1       \ncurrent       16.77           40.88     \n              59.62           24.46     \n          1.510-332.204   0.619-136.307 \n--------------------------------------- \n\n\nShow the code\ndt_rates &lt;- pyears(Surv(tstart, tstop,chd) ~ smok3+grade+ageband,\n       data = white_split,\n       scale=1,\n       data.frame = T)\n# ageband is coded as numeric in the output\ndt_rates$data$ageband &lt;- as.factor(dt_rates$data$ageband)\nmod1 &lt;-  glm(event ~ grade+smok3 + ageband+offset(log(pyears)),\n      family = poisson,\n      data= dt_rates$data) \ntbl_regression(mod1,exponentiate = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\ngrade\n\n\n\n\n\n\n\n\n    higher\n—\n—\n\n\n\n\n    lower\n1.27\n0.91, 1.78\n0.2\n\n\nsmok3\n\n\n\n\n\n\n\n\n    never\n—\n—\n\n\n\n\n    ex\n2.11\n1.15, 4.26\n0.024\n\n\n    current\n3.12\n1.73, 6.20\n&lt;0.001\n\n\nageband\n\n\n\n\n\n\n\n\n    2\n—\n—\n\n\n\n\n    3\n6.09\n1.15, 112\n0.086\n\n\n    4\n8.26\n1.70, 149\n0.040\n\n\n    5\n17.3\n3.76, 308\n0.005\n\n\n    6\n25.3\n5.50, 449\n0.001\n\n\n    7\n31.3\n6.67, 558\n&lt;0.001\n\n\n    8\n42.4\n8.53, 768\n&lt;0.001\n\n\n    9\n80.8\n11.9, 1,587\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\n\n\nShow the code\nmod_int &lt;-  glm(event ~ grade*smok3 + ageband+offset(log(pyears)),\n      family = poisson,\n      data= dt_rates$data) \nlmtest::lrtest(mod1,mod_int)\n\n\n\n\n\n\n#Df\nLogLik\nDf\nChisq\nPr(&gt;Chisq)\n\n\n\n\n11\n-75\nNA\nNA\nNA\n\n\n13\n-74\n2\n1.2\n0.53\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is no evidence of effect modification between grade and smoking. \\(\\chi_{2}^2 = 1.25\\) and p=0.53\n\n\n\n\n\nQ12\nThe file whchd.dta holds the Whitehall data already expanded by current age and period (in 5-years periods) and has been stset for the analysis of CHD events. It also holds a variable, called rate, giving the corresponding age and period specific CHD mortality rates for England and Wales (per 1,000,000 person years). Compute the CHD SMR for the cohort of Whitehall civil servants\n\n\nShow the code\n# way more complicated than STATA (using this format of data)\n# the stranges names from stata dont work verwy well in R - use clean_names to fix\nwhcd &lt;- haven::read_dta(\"datasets/WHCHD.DTA\") |&gt; janitor::clean_names()\n# get the expected number of cases - adjusted by period, ageband and grade\n\nexpectdt &lt;- whcd |&gt; group_by(ageband, grade, period) |&gt; \n  reframe(a=mean(rate)/1e6,\n          totalpy=sum(t-t0)) |&gt; \n  reframe(e=a*totalpy) |&gt; \n  reframe(sum(e))\n\n\nobservedt &lt;- whcd |&gt; \n  reframe(sum(chd, na.rm=T))\n\npopEpi::poisson.ci(147,227)\n\n\n\n\n\n\nx\npt\nrate\nlower\nupper\nconf.level\n\n\n\n\n147\n227\n0.65\n0.55\n0.76\n0.95",
    "crumbs": [
      "Home",
      "06: Stratifying on time for cohort studies"
    ]
  },
  {
    "objectID": "ASME_07.html",
    "href": "ASME_07.html",
    "title": "07: Poisson regression for cohort studies",
    "section": "",
    "text": "Show the code\n# read \"dta\" files\nlibrary(haven) \n# create table\nlibrary(gtsummary)\n# data wrangling and other functions\nlibrary(tidyverse)\n# if you want to have a output similar to stata\nlibrary(tidylog)\n#cox\nlibrary(survival)\n# plots survival\nlibrary(ggsurvfit)\n# Limit significant digits to 2, remove scientific notation\noptions(digits = 2, scipen = 9)\n\n\nThe following questions refer to the dataset ondrate.dta. This contains data on 1536 individuals living in an onchocercal zone in Nigeria, who were followed over a period up to 3 years to study the incidence of optic nerve disease (OND) and the extent to which onchocerciasis is a risk factor for OND.\n\nQ1\nUse the desc-STATA / glimpse() and list(STATA) / str() commands to find out what information the dataset contains.\n\n\nShow the code\nondrate &lt;- read_stata(\"datasets/ondrate.dta\")\n\nglimpse(ondrate)\n\n\nRows: 1,536\nColumns: 8\n$ id      &lt;dbl&gt; 18, 23, 30, 39, 42, 43, 48, 56, 62, 63, 72, 73, 75, 78, 79, 90…\n$ disc2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,…\n$ age     &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1…\n$ sex     &lt;dbl&gt; 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1,…\n$ mfpermg &lt;dbl+lbl&gt; 2, 0, 2, 2, 1, 0, 1, 0, 2, 1, 2, 2, 2, 1, 2, 1, 2, 0, 0, 0…\n$ pyrs    &lt;dbl&gt; 2.7, 1.9, 2.7, 2.7, 2.7, 2.8, 2.7, 2.7, 2.7, 1.9, 2.7, 2.7, 2.…\n$ start   &lt;date&gt; 1983-01-01, 1983-01-01, 1983-01-01, 1983-01-01, 1983-01-01, 1…\n$ end     &lt;date&gt; 1985-09-27, 1984-11-28, 1985-09-27, 1985-09-27, 1985-09-27, 1…\n\n\nShow the code\nondrate &lt;- read_stata(\"datasets/ondrate.dta\") |&gt; \n  mutate(across(where(is.labelled),as_factor))\n# alternative\n#str(ondrate)\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nAge is coded as numeric, but it is a categorical variable in the original dataset. We can convert all variables with labels (STATA) to factor. The code mutate(across(where(is.labelled),as_factor)) checks if a column has labels, if it has, convert to factor\n\n\n\n\n\nQ2\nUse the strate(STATA)/ pyears() command to examine the patterns of incidence of OND by age, sex and microfilarial load (a measure of the intensity of onchocercal infection). Don’t forget that you will need to issue the following command before you can use any st commands:\n\nShow the code\n# Rates by age\n# The default value of scale in\npyears(Surv(time = as.numeric(start), \n                         time2 = as.numeric(end), \n                         event = disc2) ~ age, ondrate, scale = 365.25) %&gt;% summary(n = F, rate = T, ci.r = T, scale = 1000)\n\nCall: pyears(formula = Surv(time = as.numeric(start), time2 = as.numeric(end), event = disc2) ~ age, data = ondrate, scale = 365.25)\nnumber of observations = 1536\n\n\n\nage\nEvents\nTime\nEvent rate\nCI (rate)\n\n\n\n\n&lt;35\n19\n2352\n8.1\n4.9 - 13\n\n\n35-44\n16\n812\n19.7\n11.3 - 32\n\n\n45-54\n20\n453\n44.2\n27.0 - 68\n\n\n55+\n16\n285\n56.1\n32.0 - 91\n\n\n\n\nShow the code\n# Rates by sex\npyears(Surv(time = as.numeric(start), \n                         time2 = as.numeric(end), \n                         event = disc2) ~ sex, ondrate)  |&gt;  summary(n = F, rate = T, ci.r = T, scale = 1000)\n\nCall: pyears(formula = Surv(time = as.numeric(start), time2 = as.numeric(end), event = disc2) ~ sex, data = ondrate)\nnumber of observations = 1536\n\n\n\nsex\nEvents\nTime\nEvent rate\nCI (rate)\n\n\n\n\n1\n38\n1858\n20\n14 - 28\n\n\n2\n33\n2044\n16\n11 - 23\n\n\n\n\nShow the code\n# Rates by microfilarial load\npyears(Surv(time = as.numeric(start), \n                         time2 = as.numeric(end), \n                         event = disc2) ~ mfpermg, ondrate)  |&gt;  summary(n = F, rate = T, ci.r = T, scale = 1000)\n\nCall: pyears(formula = Surv(time = as.numeric(start), time2 = as.numeric(end), event = disc2) ~ mfpermg, data = ondrate)\nnumber of observations = 1536\n\n\n\nmfpermg\nEvents\nTime\nEvent rate\nCI (rate)\n\n\n\n\n0\n14\n1157\n12\n6.6 - 20\n\n\n1-9.99\n18\n1511\n12\n7.1 - 19\n\n\n10+\n39\n1233\n32\n22.5 - 43\n\n\n\n\n\nQ3\nUsing the streg(STATA) / glm command and the dist(exp)(STATA)/family=poisson option, fit simple Poisson regression models to estimate (separately) the crude effects of age, sex and microfilarial load on OND incidence. Compare the rate ratio estimates obtained from streg (STATA)/glm (Poisson regression) with those obtained using stmh.\n(As explained in Pratical 6 - Q9, it is painfull to do mantel haenszel rate ratio in R and there is no gain in conduct MH instead Poisson regression)\n\n\nShow the code\n# Age\nglm(disc2 ~ age + offset(log(pyrs)),\n    family = poisson,\n    data = ondrate)  |&gt; \n  tbl_regression(exponentiate=T) |&gt; \n  modify_caption(caption = \"Age\")\n\n\n\n\n\n\nAge\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\nAge at start\n\n\n\n\n\n\n\n\n    &lt;35\n—\n—\n\n\n\n\n    35-44\n2.44\n1.24, 4.74\n0.009\n\n\n    45-54\n5.47\n2.91, 10.3\n&lt;0.001\n\n\n    55+\n6.94\n3.52, 13.5\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nShow the code\n# Sex\nglm(disc2 ~ sex + offset(log(pyrs)),\n    family = poisson,\n    data = ondrate)  |&gt; \n  tbl_regression(exponentiate=T) |&gt; \n  modify_caption(caption = \"Sex\")\n\n\n\n\n\n\nSex\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\nSex: 1=male, 2=female\n0.79\n0.49, 1.26\n0.3\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nShow the code\n# Microfilarial load\nglm(disc2 ~ mfpermg + offset(log(pyrs)),\n    family = poisson,\n    data = ondrate)  |&gt; \n  tbl_regression(exponentiate=T) |&gt; \n  modify_caption(caption = \"Microfilarial load\")\n\n\n\n\n\n\nMicrofilarial load\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\nMicrofilariae per mg\n\n\n\n\n\n\n\n\n    0\n—\n—\n\n\n\n\n    1-9.99\n0.98\n0.49, 2.01\n&gt;0.9\n\n\n    10+\n2.61\n1.45, 4.98\n0.002\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\n\n\nQ4\nAre either age or sex associated with microfilarial load (MfL)? Which, if either, are likely to confound the association between microfilarial load and incidence of OND?\n\n\nShow the code\nondrate |&gt; \n  tbl_summary(by = mfpermg,\n              include = c(age,sex)) |&gt; \n  add_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n0 N = 4711\n1-9.99 N = 5881\n10+ N = 4771\np-value2\n\n\n\n\nAge at start\n\n\n\n\n\n\n0.019\n\n\n    &lt;35\n315 (67%)\n342 (58%)\n268 (56%)\n\n\n\n\n    35-44\n78 (17%)\n136 (23%)\n106 (22%)\n\n\n\n\n    45-54\n48 (10%)\n70 (12%)\n60 (13%)\n\n\n\n\n    55+\n30 (6.4%)\n40 (6.8%)\n43 (9.0%)\n\n\n\n\nSex: 1=male, 2=female\n\n\n\n\n\n\n0.12\n\n\n    1\n211 (45%)\n278 (47%)\n245 (51%)\n\n\n\n\n    2\n260 (55%)\n310 (53%)\n232 (49%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMfL of males and females is similar. Age is potential confounder, sex is unlikely to be\n\n\n\n\n\nQ5\nUse Poisson regression to obtain rate ratio estimates for microfilarial load adjusted for (i) age, (ii) sex, (iii) both age and sex. Is there any indication of confounding?\n\n\nShow the code\n# Age\ntbl_age &lt;- glm(disc2 ~ mfpermg + age + offset(log(pyrs)),\n    family = poisson,\n    data = ondrate)  |&gt; \n  tbl_regression(exponentiate=T) \n\n# Sex\ntbl_sex &lt;- glm(disc2 ~ mfpermg+ sex + offset(log(pyrs)),\n    family = poisson,\n    data = ondrate)  |&gt; \n  tbl_regression(exponentiate=T) \n\n# Microfilarial load\ntbl_both &lt;- glm(disc2 ~ mfpermg +sex+age+ offset(log(pyrs)),\n    family = poisson,\n    data = ondrate)  |&gt; \n  tbl_regression(exponentiate=T) \n\n\ntbl_merge(list(\n  tbl_age,\n  tbl_sex,\n  tbl_both\n  ),\n         tab_spanner = c(\"**Adjusted for Age**\", \"**Sex**\",\n                         \"**Both**\") )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nAdjusted for Age\n\n\nSex\n\n\nBoth\n\n\n\nIRR\n95% CI\np-value\nIRR\n95% CI\np-value\nIRR\n95% CI\np-value\n\n\n\n\nMicrofilariae per mg\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    0\n—\n—\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    1-9.99\n0.91\n0.45, 1.87\n0.8\n0.98\n0.49, 2.01\n&gt;0.9\n0.92\n0.46, 1.88\n0.8\n\n\n    10+\n2.28\n1.26, 4.35\n0.008\n2.59\n1.44, 4.94\n0.002\n2.28\n1.27, 4.36\n0.008\n\n\nAge at start\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    &lt;35\n—\n—\n\n\n\n\n\n\n\n\n—\n—\n\n\n\n\n    35-44\n2.37\n1.20, 4.61\n0.011\n\n\n\n\n\n\n2.34\n1.19, 4.57\n0.012\n\n\n    45-54\n5.27\n2.80, 9.95\n&lt;0.001\n\n\n\n\n\n\n5.24\n2.78, 9.89\n&lt;0.001\n\n\n    55+\n6.37\n3.23, 12.4\n&lt;0.001\n\n\n\n\n\n\n6.32\n3.20, 12.3\n&lt;0.001\n\n\nSex: 1=male, 2=female\n\n\n\n\n\n\n0.82\n0.51, 1.31\n0.4\n0.88\n0.55, 1.40\n0.6\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nCompared with the crude rate ratios, the age-adjusted rate ratios for MfL groups 1-9.99 and 10+ are somewhat reduced, indicating some confounding as expected (those with high MfL tend to be older and at greater risk because of their older age).\nAdjusting for sex has little impact on the mf load rate ratios, indicating little or no confounding (again as expected – little difference in mf load between the sexes). Adjusting for sex in addition to age changes the mf load rate ratios only slightly. There is no evidence (Wald test p-value of 0.587) that sex is associated with OND.\n\n\n\n\n\nQ6\nPoisson regression models assume, unless you include interaction terms, that effects of different variables combine multiplicatively. Is there any evidence of an interaction between age and microfilarial load? Between sex and microfilarial load?\nSex\n\n\nShow the code\ntbl_no_int &lt;- glm(disc2 ~ mfpermg +sex+ offset(log(pyrs)),\n    family = poisson,\n    data = ondrate) \ntbl_w_int &lt;- glm(disc2 ~ mfpermg*sex+ offset(log(pyrs)),\n    family = poisson,\n    data = ondrate) \nlmtest::lrtest(tbl_no_int,tbl_w_int)\n\n\n\n\n\n\n#Df\nLogLik\nDf\nChisq\nPr(&gt;Chisq)\n\n\n\n\n4\n-276\nNA\nNA\nNA\n\n\n6\n-275\n2\n0.31\n0.86\n\n\n\n\n\n\nAge\n\n\nShow the code\ntbl_no_int &lt;- glm(disc2 ~ mfpermg +age+ offset(log(pyrs)),\n    family = poisson,\n    data = ondrate) \ntbl_w_int &lt;- glm(disc2 ~ mfpermg*age+ offset(log(pyrs)),\n    family = poisson,\n    data = ondrate) \nlmtest::lrtest(tbl_no_int,tbl_w_int)\n\n\n\n\n\n\n#Df\nLogLik\nDf\nChisq\nPr(&gt;Chisq)\n\n\n\n\n6\n-256\nNA\nNA\nNA\n\n\n12\n-251\n6\n9.1\n0.17\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe likelihood ratio test for sex produces p=0.856, so there is no evidence of an interaction between mf load and sex. i.e. there is no evidence that the effect of MfL on OND is different for males and females. Similarly, there is no evidence of an interaction between age and MfL (p=0.17), however it is important to note the number of parameters (6) used in this LRT. You could try testing age as ordinal variable (also no evidence of interaction, p = 0.14)\n\n\n\n\n\nQ7\nFitting the age variable included in the dataset as a factor introduces three parameters into the model. Would it be reasonable to treat the age variable as continuous and thus reduce the number of parameters in the model? How would you assess this?\n\n\nShow the code\ntbl_ordinal &lt;- glm(disc2 ~ as.numeric(age)+ offset(log(pyrs)),\n    family = poisson,\n    data = ondrate) \ntbl_cat &lt;- glm(disc2 ~ age+ offset(log(pyrs)),\n    family = poisson,\n    data = ondrate) \nlmtest::lrtest(tbl_ordinal,tbl_cat)\n\n\n\n\n\n\n#Df\nLogLik\nDf\nChisq\nPr(&gt;Chisq)\n\n\n\n\n2\n-264\nNA\nNA\nNA\n\n\n4\n-263\n2\n2.1\n0.34\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe likelihood ratio test shows no evidence against (or in favor) of using age as ordinal (linear)\n\n\n\n\n\nQ8\nOpen whitehal.dta and use Poisson regression to repeat the analyses in question 11 of practical 5, i.e. examine the effect of job grade on CHD mortality adjusted for ageband and smoking status simultaneously. How does the result obtained from Poisson regression compare to that obtained using the stmh command?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nQ11 of Session 6 already has it",
    "crumbs": [
      "Home",
      "07: Poisson regression for cohort studies"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LSHTM - ASME",
    "section": "",
    "text": "This site contains the solutions in R for Advanced Statistical Methods in Epidemiology (2412)"
  },
  {
    "objectID": "ASME_10.html",
    "href": "ASME_10.html",
    "title": "10: Analysis of correlated outcome data",
    "section": "",
    "text": "Show the code\nlibrary(haven) \n# create table\nlibrary(gtsummary)\n# data wrangling and other functions\nlibrary(tidyverse)\n# if you want to have a output similar to stata\nlibrary(tidylog)\n#cox\nlibrary(survival)\n# plots survival\nlibrary(ggsurvfit)\n# Limit significant digits to 2, remove scientific notation\noptions(digits = 2, scipen = 9)\n\npapua &lt;- read_dta(\"datasets/pngnew.dta\") |&gt; \n  mutate(across(where(is.labelled),as_factor))\n\n\nIn the first part of the practical we examine data from a pneumococcal vaccine trial performed in Papua New Guinea (pngnew.dta). The data are arranged by episode, so that each child in the trial may have several records, one for each episode of clinical pneumonia (without laboratory confirmation of pneumococcal infection) and, usually, one for the period from their last episode until they exited the trial. Thus, for each child we have data on the number of episodes they experienced (the numerator) and the length of time for which they were followed up (the denominator). We can thus calculate rates and rate ratios and an appropriate statistical model is a Poisson regression model with a random effect to account for between child variability in susceptibility/exposure.\n\n\n\n\n\n\nNote\n\n\n\nThese data are from a pneumococcal vaccine trial performed in Papua New Guinea, assessing the vaccine efficacy in preventing clinical episodes of pneumonia among children.\nEach child might have more than one record, because each record represents an episode of pneumonia (or the last period of follow-up, without pneumonia).\n*Outcome* : any indicates whether the current period of observation ended in an episode or not\n*Exposure* : vacc (vaccination: 1 = placebo, 2 = vaccine)\n*Cluster* : id (child)\n*Time* : -timein (date of entry in this follow-up period) -timeout (date of exit from this follow-up period) -dob (date of birth)\n*Other* - sex (1 = male, 2 = female) - anyprev (0: no previous episodes of pneumonia, 1: any prev. episodes)\n\n\n\nQ1\nEach child had a unique identification number (id) which identifies which records belong to which child. Examine the data for child id 2921:\n\n\nShow the code\npapua &lt;- papua |&gt; \n  mutate(sex = factor(sex, levels = c(1, 2), labels = c(\"male\", \"female\")),\n                 vacc = factor(vacc, levels = c(1, 2), labels = c(\"placebo\", \"vaccine\")),\n                 pyrs = as.numeric(timeout - timein) / 365.25)\n\n\npapua |&gt; \n  filter(id==2921)\n\n\n# A tibble: 5 × 10\n     id sex   vacc      any anyprev timein     timeout    dob        datevac   \n  &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n1  2921 male  placebo     1       0 1981-10-26 1982-04-07 1976-12-08 1981-10-26\n2  2921 male  placebo     1       1 1982-04-07 1982-10-18 1976-12-08 1981-10-26\n3  2921 male  placebo     1       2 1982-10-18 1983-05-04 1976-12-08 1981-10-26\n4  2921 male  placebo     1       3 1983-05-04 1983-05-25 1976-12-08 1981-10-26\n5  2921 male  placebo     0       4 1983-05-25 1983-11-30 1976-12-08 1981-10-26\n# ℹ 1 more variable: pyrs &lt;dbl&gt;\n\n\n\n\nQ2\nIndividual children can have multiple records in the database, depending on how many episodes of clinical pneumonia they experienced. Use the following commands to examine the number of children in each vaccine group and the number of episodes per child\n\n\nShow the code\npapua |&gt; group_by(id) |&gt; \n  summarise(episodes = sum(any),\n            vacc = max(as.numeric(vacc))) |&gt; \n  mutate(episodes = as.character(episodes)) |&gt; \n  tbl_summary(include = episodes, by = vacc)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n1 N = 7191\n2 N = 6711\n\n\n\n\nepisodes\n\n\n\n\n\n\n    0\n225 (31%)\n242 (36%)\n\n\n    1\n183 (25%)\n155 (23%)\n\n\n    10\n0 (0%)\n1 (0.1%)\n\n\n    11\n2 (0.3%)\n0 (0%)\n\n\n    2\n131 (18%)\n114 (17%)\n\n\n    3\n73 (10%)\n72 (11%)\n\n\n    4\n53 (7.4%)\n46 (6.9%)\n\n\n    5\n24 (3.3%)\n23 (3.4%)\n\n\n    6\n14 (1.9%)\n6 (0.9%)\n\n\n    7\n10 (1.4%)\n5 (0.7%)\n\n\n    8\n3 (0.4%)\n4 (0.6%)\n\n\n    9\n1 (0.1%)\n3 (0.4%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nCompared to STATA, you dont need to worry about the dataset being modified unintentionally (R&gt;Stata). The coding is grouping the individuals by id and doing operations in each small dataset (all rows from each id). sum(any) sums all values in the “any” variable, max(as.numeric(vacc)) is a workaround of recovering the group, as each participant is either vaccinated or unvaccinated. This approach wouldn’t work if the participant could be vaccinated after enter the study\n\n\n\nDetermine how many episodes there were in total in each vaccine group\n\n\nShow the code\npapua |&gt; group_by(vacc) |&gt; summarise(episodes = sum(any))\n\n\n# A tibble: 2 × 2\n  vacc    episodes\n  &lt;fct&gt;      &lt;dbl&gt;\n1 placebo     1205\n2 vaccine     1038\n\n\n\n\nQ3\nThings you dont need to do in R.\n\n\nQ4\nExamine the incidence rates in the vaccinated and unvaccinated groups, and to calculate a rate ratio, ignoring any within-child clustering.\n\n\nShow the code\npyears(Surv(pyrs,any) ~ vacc, data = papua, scale = 1) %&gt;%\n  summary(n = F, rate = T, ci.r = T, scale = 100)\n\n\nCall: pyears(formula = Surv(pyrs, any) ~ vacc, data = papua, scale = 1)\n\nnumber of observations = 3627\n\n  vacc     Events   Time   Event rate   CI (rate)  \n--------- -------- ------ ------------ ----------- \n placebo    1205    1217       99       94 - 105  \n vaccine    1038    1160       90       84 -  95  \n\n\nRate ratio (using Poisson and not MH - Stata solution)\n\n\nShow the code\ndt_pois &lt;- (pyears(Surv(pyrs,any) ~ vacc, data = papua, scale = 1,\n       data.frame = T))$data \n  glm(event~vacc + offset(log(pyears)), family=poisson,\n      data=dt_pois) |&gt; \n    tbl_regression(exponentiate = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\nvacc\n\n\n\n\n\n\n\n\n    placebo\n—\n—\n\n\n\n\n    vaccine\n0.90\n0.83, 0.98\n0.017\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nShow the code\n    glm(event~vacc + offset(log(pyears)), family=poisson,\n      data=dt_pois) |&gt; \n    tbl_regression(exponentiate = F) |&gt; \n    modify_column_unhide(column = std.error) #trick to show SE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nlog(IRR)\nSE\n95% CI\np-value\n\n\n\n\nvacc\n\n\n\n\n\n\n\n\n\n\n    placebo\n—\n—\n—\n\n\n\n\n    vaccine\n-0.10\n0.042\n-0.18, -0.02\n0.017\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio, SE = Standard Error\n\n\n\n\n\n\n\n\n\n\nQ5\nRefit the Poisson regression model, this time asking Stata to compute robust standard errors adjusted for clustering. What impact does taking account of the clustering have on your interpretation of the vaccine’s effect?\nWe have multiple options to calculate cluster robust SE in R.\n\n\nShow the code\n# Using the miceadds package (not my preferred option)\n# pois_rob &lt;- miceadds::glm.cluster(papua,\n#                         any ~ vacc + offset(log(pyrs)),\n#                         cluster = \"id\",\n#                         family = \"poisson\")\n# summary(pois_rob)\n\n\n\n\nShow the code\n# using sandwich and lmtest\nlibrary(sandwich)\nlibrary(lmtest)\npois_no_cluster &lt;- glm(any ~ vacc + offset(log(pyrs)),\n                family = \"poisson\",\n                data = papua)\ncoeftest(pois_no_cluster, vcov = vcovCL, cluster = ~ id)\n\n\n\nz test of coefficients:\n\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept) -0.00973    0.04172   -0.23    0.816  \nvaccvaccine -0.10117    0.06087   -1.66    0.097 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nShow the code\n# using parameters::model_parameters (requires sandwich package)\nparameters::model_parameters(\n  pois_no_cluster,\n  vcov = \"vcovCL\",\n  vcov_args = list(cluster=papua$id),\n  exponentiate=T\n)\n\n\nParameter      |  IRR |   SE |       95% CI |     z |     p\n-----------------------------------------------------------\n(Intercept)    | 0.99 | 0.04 | [0.91, 1.07] | -0.23 | 0.816\nvacc [vaccine] | 0.90 | 0.06 | [0.80, 1.02] | -1.66 | 0.097\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe SE increased from 0.042 to 0.061 (log IRR)\n\n\n\n\n\nQ6\nNow fit a random effects model to take account of within child clustering.\n\n\nShow the code\nmod_gamma &lt;- coxph(Surv(pyrs, any) ~ vacc + frailty(id, \n    distribution = \"gamma\"), data = papua)\ntbl_regression(mod_gamma,\n               exponentiate = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nvacc\n\n\n\n\n\n\n\n\n    placebo\n—\n—\n\n\n\n\n    vaccine\n0.88\n0.77, 1.00\n0.046\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nWe are using a Cox regression with a fraitly term. In the stata exercise, it has been calculated using a parametric model\n\n\n\n\n\nQ7\n\n\nShow the code\nlibrary(lme4)\n# Fit model\npois_re &lt;- glmer(any ~ vacc + offset(log(pyrs)) + (1|id),\n                 data = papua,\n                 family = \"poisson\")\n\nsummary(pois_re)\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: any ~ vacc + offset(log(pyrs)) + (1 | id)\n   Data: papua\n\n     AIC      BIC   logLik deviance df.resid \n    9758     9777    -4876     9752     3624 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.554 -0.654  0.095  1.021 17.376 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 0.673    0.821   \nNumber of obs: 3627, groups:  id, 1390\n\nFixed effects:\n            Estimate Std. Error z value    Pr(&gt;|z|)    \n(Intercept)  -0.2704     0.0477   -5.67 0.000000014 ***\nvaccvaccine  -0.1213     0.0648   -1.87       0.061 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nvaccvaccine -0.632\n\n\n\n\nShow the code\n# Output\nbroom.mixed::tidy(pois_re,\n     conf.int = TRUE,\n     exponentiate = TRUE,\n     effects = \"fixed\")\n\n\n# A tibble: 2 × 8\n  effect term        estimate std.error statistic     p.value conf.low conf.high\n  &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 fixed  (Intercept)    0.763    0.0364     -5.67     1.43e-8    0.695     0.838\n2 fixed  vaccvaccine    0.886    0.0574     -1.87     6.10e-2    0.780     1.01 \n\n\n\n\nQ8\nFit the model using age, instead time since study entry\n\n\nShow the code\nmod_gamma &lt;- coxph(Surv(time = as.numeric(timein),\n                        time2 = as.numeric(timeout),\n                        origin = as.numeric(dob),\n                        any) ~ vacc + frailty(id, \n    distribution = \"gamma\"), data = papua)\ntbl_regression(mod_gamma,\n               exponentiate = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nvacc\n\n\n\n\n\n\n\n\n    placebo\n—\n—\n\n\n\n\n    vaccine\n0.91\n0.83, 1.01\n0.078\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\n\nQ9\nRefit the random effects model also adjusting for age and sex.\n\n\nShow the code\npapua &lt;- papua |&gt; \n  mutate(age_years = as.numeric((timein - dob)/365.25))\npois_re &lt;- glmer(any ~ vacc + offset(log(pyrs)) + \n                   age_years+\n                   sex+\n                   (1|id),\n                 data = papua,\n                 family = \"poisson\")\n\npapua&lt;- papua |&gt; \n  mutate(agegrp = cut(age_years,\n                              breaks = c(0, 1, 2, 3, 4,+Inf),\n                              labels = c(\"0-1yr,\", \"1-2yr\", \"2-3yr\", \"3-4yr\", \"&gt;=4yr\")))\n# Output\ntbl_cont &lt;- pois_re |&gt; \n  tbl_regression(exponentiate=T)\n\npois_re_grp &lt;- glmer(any ~ vacc + offset(log(pyrs)) + \n                   agegrp+\n                     sex+\n                   (1|id),\n                 data = papua,\n                 family = \"poisson\")\n\ntbl_cat &lt;- pois_re_grp |&gt; \n  tbl_regression(exponentiate=T)\n\ntbl_merge(\n  list(tbl_cont, tbl_cat),\n  tab_spanner = c(\"Continuous age\",\"Categorical age\")\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nContinuous age\n\n\nCategorical age\n\n\n\nIRR\n95% CI\np-value\nIRR\n95% CI\np-value\n\n\n\n\nvacc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    placebo\n—\n—\n\n\n—\n—\n\n\n\n\n    vaccine\n0.90\n0.81, 1.01\n0.073\n0.91\n0.82, 1.02\n0.10\n\n\nage_years\n0.63\n0.61, 0.66\n&lt;0.001\n\n\n\n\n\n\n\n\nsex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    male\n—\n—\n\n\n—\n—\n\n\n\n\n    female\n1.02\n0.91, 1.14\n0.7\n1.02\n0.92, 1.14\n0.7\n\n\nagegrp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    0-1yr,\n\n\n\n\n\n\n—\n—\n\n\n\n\n    1-2yr\n\n\n\n\n\n\n0.67\n0.59, 0.76\n&lt;0.001\n\n\n    2-3yr\n\n\n\n\n\n\n0.41\n0.35, 0.47\n&lt;0.001\n\n\n    3-4yr\n\n\n\n\n\n\n0.29\n0.25, 0.34\n&lt;0.001\n\n\n    &gt;=4yr\n\n\n\n\n\n\n0.16\n0.14, 0.19\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nControlling for age and sex results in an adjusted rate ratio of 0.91, compared with an unadjusted rate ratio of 0.88. The evidence for a vaccine effect has weakened a little (P-value is now 0.10). Given that this was a fairly large RCT we would not expect strong confounding by age or sex (this can be checked by cross-tabulating age and sex at enrolment against vaccine group).\n\n\n\n\n\nQ10\nOpen the data set (hhtb.dta) and explore the dataset (glimpse) or click on it in the environment tab.\n\nOutcome : mantoux (tuberculin test result: 0 = negative, 1 = positive)\nExposure: cough (duration of cough in index case: 1 = &lt;2 months, 2 = &gt;=2 months)\nCluster: id (household, so = index case)\nhiv - hiv (HIV status of index case: 1 = negative, 2 = positive)\nage group: agegrp (age of contact, in years)\n\n\n\nShow the code\nhhtb &lt;- read_dta(\"datasets/HHTB.DTA\") |&gt; \n  mutate(across(where(is.labelled),as_factor))\n\n#glimpse(hhtb)\n\n\n\n\nQ11\nEach record represents an individual household contact of a TB case. The variable id indicates which household contacts belong to the same household (and hence are contacts of the same index case). Use the following commands to examine the distribution of contacts per household by HIV status of the index case.\n\n\nShow the code\nhhtb |&gt; \n  group_by(id, hiv) |&gt; \n  count(mantoux) |&gt; \n  filter(mantoux==1) |&gt; \n  mutate(hiv= as.factor(hiv)) |&gt; \n  ggplot()+\n  geom_histogram(aes(n, fill=hiv),\n                 position = \"dodge\")+\n  scale_x_continuous(breaks = seq(1:10))\n\n\n\n\n\n\n\n\n\nShow the code\n# same answer from stata\n# hhtb |&gt; \n#   group_by(id) |&gt; \n#   count(hiv) |&gt; \n#   filter(!is.na(hiv)) |&gt;\n#   ungroup() |&gt; \n#   mutate(n = factor(n, sort(unique(n)), ordered = T)) |&gt; \n#   tbl_summary(include = n, by = hiv)\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe answer in STATA show you the table. I would rather see the distribution with a histogram. Here is showing the distribution of number of cases (mantoux=1) per household and HIV status.\n\n\n\n\n\nQ12\nPerform a similar analysis to examine the distribution of contacts per household by duration of cough of the index case. Why are only 58 households shown?\n\n\nShow the code\nhhtb |&gt; \n  group_by(id) |&gt; \n  count(cough) |&gt; \n  filter(!is.na(cough)) |&gt;\n  ungroup() |&gt; \n  mutate(n = factor(n, sort(unique(n)), ordered = T)) |&gt; \n  tbl_summary(include = n, by = cough)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n1 N = 321\n2 N = 261\n\n\n\n\nn\n\n\n\n\n\n\n    1\n5 (16%)\n2 (7.7%)\n\n\n    2\n3 (9.4%)\n5 (19%)\n\n\n    3\n5 (16%)\n7 (27%)\n\n\n    4\n5 (16%)\n4 (15%)\n\n\n    5\n4 (13%)\n2 (7.7%)\n\n\n    6\n2 (6.3%)\n4 (15%)\n\n\n    8\n3 (9.4%)\n1 (3.8%)\n\n\n    9\n2 (6.3%)\n1 (3.8%)\n\n\n    10\n1 (3.1%)\n0 (0%)\n\n\n    11\n1 (3.1%)\n0 (0%)\n\n\n    13\n1 (3.1%)\n0 (0%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\n\n\nQ13\nFor household contacts, examine the distribution of tuberculin positivity by the duration of cough in the index case. Ignoring any clustering, what is the estimated odds ratio and associated 95% c.i.? What would you conclude about the association between duration of cough in the index case and tuberculin positivity in household contacts on the basis of this analysis (if you were unaware of the clustering issue)?\n\n\nShow the code\ntable(hhtb$mantoux,hhtb$cough) |&gt; \n  fisher.test() \n\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table(hhtb$mantoux, hhtb$cough)\np-value = 0.04\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 1.0 3.1\nsample estimates:\nodds ratio \n       1.8 \n\n\nShow the code\ntab1 &lt;- table(hhtb$mantoux,\n              hhtb$cough)\nepiR::epi.2by2(dat = tab1, method = \"cohort.count\", conf.level = 0.95, units = 100, \n   interpret = FALSE, outcome = \"as.columns\")\n\n\n             Outcome +    Outcome -      Total                 Inc risk *\nExposed +           72           33        105     68.57 (58.78 to 77.28)\nExposed -           82           67        149     55.03 (46.68 to 63.18)\nTotal              154          100        254     60.63 (54.33 to 66.68)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nInc risk ratio                                 1.25 (1.03, 1.51)\nInc odds ratio                                 1.78 (1.06, 3.01)\nAttrib risk in the exposed *                   13.54 (1.59, 25.48)\nAttrib fraction in the exposed (%)            19.74 (2.51, 33.93)\nAttrib risk in the population *                5.60 (-4.40, 15.59)\nAttrib fraction in the population (%)         9.23 (0.49, 17.20)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 4.729 Pr&gt;chi2 = 0.030\nFisher exact test that OR = 1: Pr&gt;chi2 = 0.037\n Wald confidence limits\n CI: confidence interval\n * Outcomes per 100 population units \n\n\nShow the code\nmod &lt;- glm(mantoux~ cough, family=binomial, data=hhtb)\nparameters::model_parameters(mod, exponentiate=T)\n\n\nParameter   | Odds Ratio |   SE |       95% CI |     z |     p\n--------------------------------------------------------------\n(Intercept) |       0.64 | 0.25 | [0.30, 1.36] | -1.16 | 0.247\ncough       |       1.78 | 0.48 | [1.06, 3.03] |  2.16 | 0.030\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nWe can get odds ratios through multiple ways. None of them matched with STATA solution (Why use MH when there is no stratification?!)\n\n\n\n\n\nQ14\nUsing the logit command, obtain a 95% confidence interval for the odds ratio based on the robust standard error taking account of clustering. Are your conclusions about the association between duration of cough in the index case and tuberculin positivity in household contacts different from question 13 above?\n\n\nShow the code\nparameters::model_parameters(\n  mod,\n  vcov = \"vcovCL\",\n  vcov_args = list(cluster=hhtb$id),\n  exponentiate=T\n)\n\n\nParameter   | Odds Ratio |   SE |       95% CI |     z |     p\n--------------------------------------------------------------\n(Intercept) |       0.64 | 0.32 | [0.24, 1.73] | -0.88 | 0.377\ncough       |       1.78 | 0.62 | [0.90, 3.52] |  1.67 | 0.096\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe confidence interval has widened to (0.90, 3.52) and we should be (even) more sceptical than before about the strength of evidence for an association (P having increased from 0.03 to 0.10). After taking clustering into account, there is only weak evidence against the null hypothesis.\n\n\n\n\n\nQ15\nNow estimate the odds ratio and obtain confidence intervals based on the GEE approach with robust standard errors and assuming an exchangeable correlation matrix. How do your results change from those in question 14?\n\n\nShow the code\nlibrary(geepack)\n# observations from the same id should be contiguous\ndep_gee &lt;- geeglm(mantoux ~ cough,\n               data = drop_na(hhtb, cough),  #geeglm doesnt accept missing values\n               id = id, \n               family = \"binomial\",\n               corstr = \"exchangeable\")\nparameters::model_parameters(dep_gee, exponentiate=T)\n\n\nParameter   | Odds Ratio |   SE |       95% CI | Chi2(1) |     p\n----------------------------------------------------------------\n(Intercept) |       0.58 | 0.30 | [0.21, 1.60] |    1.10 | 0.294\ncough       |       1.88 | 0.65 | [0.95, 3.71] |    3.27 | 0.071\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe point estimate of the odds ratio for duration of cough is 1.87 with 95% c.i. (0.97, 3.60), P=0.07. The odds ratio is slightly larger than that obtained using only robust standard errors (1.78). The standard error of the log odds ratio is very similar to that obtained from the previous “robust” analysis (0.35 ~ 0.35).\nThe PI and CI in Stata is different: 1.88 with 95% c.i. (0.94, 3.73) (I dont know why)\n\n\n\n\n\nQ16\nUse the xtlogit command again, but this time with the re option, to fit a random effects model for tuberculin positivity in terms of the duration of cough in the index case. Is there evidence from this model of between-household variation (within-household correlation)? Use the quadchk,nooutput command to check the reliability of the estimates from the random effects model.\n\n\nShow the code\ntb_mixed &lt;-  glmer(mantoux ~ cough + (1|id),\n                 data = hhtb,\n                 family = \"binomial\")\n\ntbl_laplace &lt;- tb_mixed |&gt; \n  tbl_regression(exponentiate=T)\n\n\n# You can get using adptative Gaussian quadrature using this\ntb_mixed &lt;-  glmer(mantoux ~ cough + (1|id),\n                 data = hhtb,\n                 family = \"binomial\",\n                 nAGQ = 12)\ntbl_quadrad &lt;- tb_mixed |&gt; \n  tbl_regression(exponentiate=T)\n\ntbl_merge(\n  list(tbl_laplace,\n       tbl_quadrad),\n  tab_spanner = c(\"Laplace\",\"Adaptative\")\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nLaplace\n\n\nAdaptative\n\n\n\nOR\n95% CI\np-value\nOR\n95% CI\np-value\n\n\n\n\nDuration of cough\n2.15\n0.96, 4.80\n0.061\n2.19\n0.94, 5.08\n0.069\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\nShow the code\n#m2 &lt;- GLMMadaptive::mixed_model(fixed = mantoux ~ cough, random = ~ 1 | id, data = hhtb,\n #                  family = binomial())\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe estimated odds ratio is 2.19 (95% c.i. 0.94, 5.08; P=0.07). The estimate of the odds ratio is larger than that obtained from the GEE analysis (1.88).\nPs.:The default of glmer function uses a Laplace approximation and not the adaptative Gaussian quadrature\n\n\n\n\n\n\n\n\n\nCoding explanation\n\n\n\n\n\nI dont think there is a similar function as “quadchk” from Stata in R. You need to refit the model with different quadrature points (nAGQ)\n\n\n\n\n\nQ17\nUse a random effects model to investigate the association between duration of cough in the index case and odds of tuberculin positivity, controlling for the effect of index cases’ HIV status and the age of the household contact, taking account of within-household clustering. Write down some sentences to summarise and interpret your results.\n\n\nShow the code\nhhtb$agegrp &lt;- factor(hhtb$agegrp)\ntb_mixed &lt;-  glmer(mantoux ~ cough + hiv +agegrp+ (1|id),\n                 data = hhtb,\n                 family = \"binomial\",\n                 nAGQ = 12)\ntb_mixed |&gt; \n  tbl_regression(exponentiate=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nDuration of cough\n1.85\n0.79, 4.31\n0.2\n\n\nHIV status of index case\n0.29\n0.12, 0.70\n0.006\n\n\nagegrp\n\n\n\n\n\n\n\n\n    1\n—\n—\n\n\n\n\n    2\n1.45\n0.69, 3.02\n0.3\n\n\n    3\n4.57\n2.11, 9.89\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn this model we have controlled for both a cluster (household) level (HIV status of the index case) and an individual level covariate (age of the contact). “After controlling for the HIV status of the index case and the age of the contact, the OR for the association between duration of cough of 2+ months and mantoux positivity is 1.85. Compared to the OR from the unadjusted random effects model (2.19) the OR is somewhat reduced suggesting some counfounding by one or both of these variables.”\n\n\n\n\n\nQ18\nUse GEE to investigate the association between duration of cough in the index case and odds of tuberculin positivity, controlling for the effect of index cases’ HIV status and the age of the household contact, taking account of within-household clustering. What do you notice about the ORs compared to those obtained with the random effects model.\n\n\nShow the code\nlogit_gee &lt;- geepack::geeglm(mantoux ~ cough + hiv + agegrp,\n                          data = drop_na(hhtb, cough),\n                          id = id,\n                          family = \"binomial\",\n                          corstr = \"exchangeable\")\nlogit_gee_noage &lt;- geepack::geeglm(mantoux ~ cough + hiv,\n                          data = drop_na(hhtb, cough),\n                          id = id,\n                          family = \"binomial\",\n                          corstr = \"exchangeable\")\n\nlogit_gee |&gt; \n  tbl_regression(exponentiate=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nDuration of cough\n1.64\n0.82, 3.30\n0.2\n\n\nHIV status of index case\n0.36\n0.18, 0.74\n0.005\n\n\nagegrp\n\n\n\n\n\n\n\n\n    1\n—\n—\n\n\n\n\n    2\n1.37\n0.68, 2.76\n0.4\n\n\n    3\n3.58\n2.26, 5.67\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAll of the ORs are closer to 1 than those when using random effects, as expected with a population average model.\n\n\n\n\n\nShow the code\nanova(logit_gee, logit_gee_noage)\n\n\nAnalysis of 'Wald statistic' Table\n\nModel 1 mantoux ~ cough + hiv + agegrp \nModel 2 mantoux ~ cough + hiv\n  Df X2  P(&gt;|Chi|)    \n1  2 31 0.00000019 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe null hypothesis is that after taking account of the index case’s HIV status and cough duration there is no association between the age of the household contact and their Mantoux test status. The alternative hypothesis is that after taking account of the index case’s HIV status and cough duration there is an association between the age of the household contact and their Mantoux test status. There is strong evidence against the null. Note that the test has 2 df because we are testing simultaneously that 2 ORs are both equal to 1.",
    "crumbs": [
      "10: Analysis of correlated outcome data"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site was built using Quarto.\nAll the material was elaborated by Thiago Cerqueira Silva, based on previous solutions by Andrea Mazzella and Julian Matthewman (https://github.com/andreamazzella/R4SME)\nPs.: In this material, I use |&gt; (native pipe operator) instead of %&gt;% (magrittr pipe). You can find it in Tools-&gt;Global Options-&gt;Code-&gt;Use native pipe operator\nPs2.: Some confidence intervals will differ from those calculated in STATA."
  }
]